{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b75ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "This script is compatibale with Registry Version v1.2.3 - 1.2.5\n",
    "    - Please look at other template \n",
    "    - Added '*' to SARS-CoV-2 Antigen* (row 163, column B)\n",
    "    - new assumptions from 1.2.5\n",
    "    Assumptions:\n",
    "        - specfiy over actaul fields \n",
    "        - loose query for v1.2.3 - 1.2.5\n",
    "        - Assessments planned visit day \n",
    "        - Treatment \n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import inspect\n",
    "import datetime as dt\n",
    "from sys import platform\n",
    "from glob import glob\n",
    "import sys\n",
    "import to_json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import argparse \n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "## Importing Functions and Dataclass\n",
    "import seronetDataclass as seroClass\n",
    "import seronetFunctions as seroFxn\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# if platform == \"darwin\":\n",
    "#     os.system('clear')\n",
    "# else:\n",
    "#     os.system('cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b3925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFBASIC = False\n",
    "TFPROTOCOL = False\n",
    "TFEXPERIMENT = False\n",
    "TFREAGENT = True\n",
    "TFASSESSMENT = False\n",
    "TFHUMAN = False\n",
    "TFORGANISM = False\n",
    "TFEXPERIMENTSAMPLE = False\n",
    "TFTREATMENT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7297d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARS_TO_CLEAN = ['', 'N/A', 'n/a', np.nan, None]\n",
    "clean_other = VARS_TO_CLEAN + ['Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e406853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full(PMID):\n",
    "# Registry\n",
    "    sheet_name = 'SeroNet Registry Template'\n",
    "    map_sheet = 'Registry Definitions'\n",
    "    EVS_DICT = 'Seronet_Study_Descriptors_v1.3_EVS.xlsx'\n",
    "    EVS_sheet = 'EVS Mapping'\n",
    "\n",
    "\n",
    "    # finding correct Box Base\n",
    "    if platform == \"darwin\":\n",
    "        box_base = \"~/Library/CloudStorage/Box-Box/SeroNet Public Data\"\n",
    "    else: \n",
    "        print(\"User has windows\")\n",
    "        box_base = os.path.join(\"Users\",os.getlogin(), \"Box\")\n",
    "\n",
    "\n",
    "    #File Paths\n",
    "    BOX_BASE = seroFxn.get_box_dir(box_base, PMID)\n",
    "    BASE_DIR = '/Users/liualg/Documents/GitHub/SeroNet/seronetTemplates/'\n",
    "\n",
    "    try:\n",
    "        df_path = glob(os.path.join(BOX_BASE,'templated_data',f'PMID{PMID}*eviewed.xlsm'))[0]\n",
    "    except:\n",
    "#         print(\"** NOT using reviewed files **\")\n",
    "        try:\n",
    "            df_path = glob(os.path.join(BOX_BASE,'templated_data',f'PMID{PMID}*.xlsm'))[0]\n",
    "        except FileNotFoundError:\n",
    "            sys.exit(\"ERROR:: Incorrect Template format. Cannot Find File\")\n",
    "        \n",
    "        \n",
    "#     df_path = os.path.join(BOX_BASE,'templated_data', file + \".xlsm\")\n",
    "#     print(\"file path: {}\".format(df_path))\n",
    "    # df_path = os.path.join(BASE_DIR,'templated_data', \"PMID34431693_registry.xlsm\")\n",
    "\n",
    "    # dictionary info\n",
    "    registryToImmportDict_file = os.path.join(\"dictionary\", \"registryToBasic.csv\")\n",
    "\n",
    "    registryToImmportDict = pd.read_csv(registryToImmportDict_file,\n",
    "                                        header=None, \n",
    "                                        index_col=0, \n",
    "                                        squeeze=True).to_dict()\n",
    "\n",
    "    # ImmPort Templates (link to web?)\n",
    "    PATH_basic_stdy_template = os.path.join(\"template\", \"basic_study_design.xlsx\")\n",
    "    PATH_protocols = os.path.join(\"template\", \"protocols.xlsx\")\n",
    "    PATH_experiments = os.path.join(\"template\", \"experiments.xlsx\") # should be tied to EXP sample + bio sample + subject\n",
    "    PATH_reagent = os.path.join(\"template\", \"reagents.Other.xlsx\") #limited to serology\n",
    "    PATH_assessment = os.path.join(\"template\", \"assessments.xlsx\")\n",
    "    PATH_subject_human = os.path.join(\"template\", \"subjectHumans.xlsx\")\n",
    "    PATH_subject_organism = os.path.join(\"template\", \"subjectAnimals.xlsx\")\n",
    "    PATH_experiment_sample = os.path.join(\"template\", \"experimentSamples.Other.xlsx\")\n",
    "    PATH_treatment = os.path.join(\"template\", \"treatments.xlsx\")\n",
    "\n",
    "\n",
    "    # Automate output... \n",
    "    OUT_DIR = os.path.join(BASE_DIR, 'DR46') \n",
    "    # OUT_DIR = './33184236_test/'\n",
    "    PATH_pmid_basic_stdy_template = f'PMID{PMID}_study.xlsx'\n",
    "\n",
    "    BASIC_STUDY_TEMPLATE = f'PMID{PMID}_basic'\n",
    "    EXP_TEMPLATE = f'PMID{PMID}_experiments'\n",
    "    PROTOCOL_TEMPLATE = f'PMID{PMID}_protocol'\n",
    "    REAGENT_TEMPLATE = f'PMID{PMID}_reagent'\n",
    "    ASSESSMENT_TEMPLATE =  f'PMID{PMID}_assessment'\n",
    "    SUBJ_HUMAN_TEMPLATE =  f'PMID{PMID}_subject_human'\n",
    "    SUBJ_ORGANISM_TEMPLATE =  f'PMID{PMID}_subject_organism'\n",
    "    EXPERIMENT_SAMPLES_TEMPLATE = f'PMID{PMID}_experiment_samples'\n",
    "    TREATMENT_TEMPALTE = f'PMID{PMID}_treatment'\n",
    "\n",
    "    # Make Dir if it does not exist\n",
    "    try:\n",
    "        os.mkdir(OUT_DIR)\n",
    "#         print(f'\\nCreating output directory - {OUT_DIR}')\n",
    "    except FileExistsError:\n",
    "#         print('\\nWill not create directory - already exists')\n",
    "        pass\n",
    "\n",
    "    # import file\n",
    "    book = load_workbook(df_path)\n",
    "    registry = book[sheet_name]\n",
    "    registry.delete_cols(1)\n",
    "\n",
    "#     print(\"\\n~~ File Information ~~\")\n",
    "\n",
    "    # In[3]:\n",
    "\n",
    "\n",
    "    # Class names\n",
    "    class_names = ['study_pubmed', 'study', 'study_personnel', 'study_file',\n",
    "                   'study_link', 'study_categorization', 'study_design',\n",
    "                   'protocol', 'condition_or_disease', 'Intervention Agent',\n",
    "                   'study_details', 'inclusion_exclusion',\n",
    "                   'Subject Type: human', 'Subject Type: model organism', 'planned_visit',\n",
    "                   'Experiments', 'Experiment Samples'\n",
    "                  ]\n",
    "\n",
    "\n",
    "\n",
    "    VARS_TO_CLEAN = ['', 'N/A', 'n/a', np.nan, None]\n",
    "    clean_other = VARS_TO_CLEAN + ['Other']\n",
    "\n",
    "    sp = seroFxn.get_sections(registry, class_names)\n",
    "    sp.append(200)\n",
    "\n",
    "    #########################################\n",
    "    ######        Main Loop       ###########\n",
    "    #########################################\n",
    "\n",
    "    # Looping through each section in the Registy template\n",
    "    for section_number in range(len(sp)-1):\n",
    "        temp_wb = Workbook()\n",
    "        temp_ws = temp_wb.active\n",
    "\n",
    "        #making a temp workbook to store each section. This will be turned into df\n",
    "        for i in registry.iter_rows(values_only = True,\n",
    "                                    min_row = sp[section_number]+1,\n",
    "                                    max_row = sp[section_number+1]-1):\n",
    "            temp_ws.append(i)\n",
    "            \n",
    "        max_row = temp_ws.max_row\n",
    "        max_col = temp_ws.max_column\n",
    "        seroFxn.remove_excess(temp_ws)\n",
    "        \n",
    "        df = pd.DataFrame(temp_ws.values)\n",
    "        sub_section = registry.cell(row=sp[section_number], column = 1).value.strip()\n",
    "        if sub_section == 'study':\n",
    "            df = seroFxn.edit_df(df)\n",
    "            \n",
    "            STUDY = seroClass.study(\n",
    "                df['Study Identifier'][1],\n",
    "                df['Study Name'][1],\n",
    "                df['Publication Title'][1],\n",
    "                df['Study Objective'][1],\n",
    "                df['Study Description'][1],\n",
    "                df['Primary Institution Name'][1]\n",
    "                )\n",
    "        \n",
    "        elif sub_section == 'study_pubmed':\n",
    "            df = seroFxn.edit_df(df)\n",
    "            \n",
    "            STUDY_PUBMED = seroClass.study_pubmed(\n",
    "                # df['Pubmed ID'][1]\n",
    "                PMID\n",
    "            )\n",
    "            \n",
    "        elif sub_section == 'study_personnel':\n",
    "            df = seroFxn.edit_df(df)\n",
    "            try:\n",
    "                STUDY_PERSONNEL = seroClass.study_personnel(\n",
    "                    df['Personnel ID'],\n",
    "                    df['Honorific'],\n",
    "                    df['Last Name'],\n",
    "                    df['First Name'],\n",
    "                    df['Suffixes'],\n",
    "                    df['Organization'],\n",
    "                    df['ORCID ID'],\n",
    "                    df['Email'],\n",
    "                    df['SeroNet Title In Study'],\n",
    "                    df['Role In Study'],\n",
    "                    df['Site Name']\n",
    "                )\n",
    "            except:\n",
    "#                 print(\"trying older format: Title in Study\")\n",
    "                STUDY_PERSONNEL = seroClass.study_personnel(\n",
    "                    df['Personnel ID'],\n",
    "                    df['Honorific'],\n",
    "                    df['Last Name'],\n",
    "                    df['First Name'],\n",
    "                    df['Suffixes'],\n",
    "                    df['Organization'],\n",
    "                    df['ORCID ID'],\n",
    "                    df['Email'],\n",
    "                    df['Title In Study'],\n",
    "                    df['Role In Study'],\n",
    "                    df['Site Name']\n",
    "                )\n",
    "\n",
    "\n",
    "        elif sub_section == 'study_file':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            STUDY_FILE = seroClass.study_file(\n",
    "                df['Study File Name'],\n",
    "                df['Study File Description'],\n",
    "                df['Study File Type']  \n",
    "            )\n",
    "            \n",
    "        \n",
    "        elif sub_section == 'study_link':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            STUDY_LINK = seroClass.study_link(\n",
    "                df['Link Name'],\n",
    "                df['Value']\n",
    "            )\n",
    "                 \n",
    "            \n",
    "        elif sub_section == 'study_categorization':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            try:\n",
    "                STUDY_CATEGORIZATION = seroClass.study_categorization(\n",
    "                    df['Research Focus*'][1],\n",
    "                    df['Study Type'][1],\n",
    "                    df['Keywords'][1],\n",
    "                )\n",
    "            except:\n",
    "                STUDY_CATEGORIZATION = seroClass.study_categorization(\n",
    "                    df['Research Focus'][1],\n",
    "                    df['Study Type'][1],\n",
    "                    df['Keywords'][1],\n",
    "            )\n",
    "        \n",
    "        elif sub_section == 'study_design':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            if (df.shape != (2,0)): # checking size. There has to be a better way to do this\n",
    "\n",
    "                STUDY_DESIGN = seroClass.study_design(\n",
    "                    df['Clinical Study Design'],\n",
    "                    df['in silico Model Type*']\n",
    "                )\n",
    "            else:\n",
    "                study_des = study_design()\n",
    "\n",
    "        elif sub_section == 'protocol':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            PROTOCOLS = seroClass.protocols(\n",
    "                df['Protocol ID'],\n",
    "                df['Protocol File Name'],\n",
    "                df['Protocol Name'],\n",
    "                df['Protocol Description'],\n",
    "                df['Protocol Type'],\n",
    "            )\n",
    "            \n",
    "        elif sub_section == 'condition_or_disease':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            COD = seroClass.condition_or_disease(\n",
    "                list(df['Reported Health Condition* '])\n",
    "            )\n",
    "            \n",
    "        elif sub_section == 'Intervention Agent':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            INTERVENTION_AGENT = seroClass.Intervention_Agent(\n",
    "                list(df['SARS-CoV-2 Vaccine Type*'])  ### IF THIS IS NOTHING, change to 'NA'\n",
    "            )\n",
    "\n",
    "        elif sub_section == 'study_details':\n",
    "            df = seroFxn.edit_df(df)\n",
    "            STUDY_DETAILS = seroClass.study_details(\n",
    "                df['Clinical Outcome Measure'][1],\n",
    "                df['Enrollment Start Date'][1],\n",
    "                df['Enrollment End Date'][1],\n",
    "                df['Number of Study Subjects'][1],\n",
    "                df['Age Unit'][1],\n",
    "                df['Minimum Age'][1],\n",
    "                df['Maximum Age'][1]\n",
    "                )\n",
    "\n",
    "        elif sub_section == 'inclusion_exclusion':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            INCLUSION_EXCLUSION = seroClass.inclusion_exclusion(\n",
    "                df['Inclusion ID'],\n",
    "                df['Inclusion Criterion'],\n",
    "                df['Inclusion Criterion Category']  \n",
    "            )\n",
    "            \n",
    "        elif sub_section == 'Subject Type: human':\n",
    "            df = seroFxn.edit_df(df)\n",
    "            tem_was_here = df\n",
    "\n",
    "            try:\n",
    "                SUBJECT_HUMAN = seroClass.subject_type_human(\n",
    "                    df['Arm ID'],\n",
    "                    df['Arm Name'],\n",
    "                    df['Study Population Description'],\n",
    "                    df['Arm Type'],\n",
    "                    df['Ethnicity*'],\n",
    "                    df['Race*'],\n",
    "                    df['Race Specify'],\n",
    "                    df['Description'],\n",
    "                    df['Sex at Birth*'],\n",
    "                    df['Age Event'],\n",
    "                    df['Subject Phenotype'],\n",
    "                    df['Study Location*'],\n",
    "                    df['Assessment Name'],\n",
    "                    df['Measured Behavioral or Psychological Factor*'],\n",
    "                    df['Measured Social Factor*'],\n",
    "                    df['SARS-CoV-2 Symptoms*'],\n",
    "                    df['Assessment_Clinical  and Demographic Data Provenance*'],\n",
    "                    df['Assessment_Demographic Data Types Collected'],\n",
    "                    df['SARS-CoV2 History*'],\n",
    "                    df['SARS-CoV-2 Vaccine Type*'],\n",
    "                    df['COVID-19 Disease Severity*'],\n",
    "                    df['Post COVID-19 Symptoms'],\n",
    "                    df['COVID-19 Complications']\n",
    "                    )\n",
    "            except:\n",
    "#                 print(\"** using older version of subject human **\")\n",
    "                SUBJECT_HUMAN = seroClass.subject_type_human(\n",
    "                    df['Arm ID'],\n",
    "                    df['Arm Name'],\n",
    "                    df['Study Population Description'],\n",
    "                    df['Arm Type'],\n",
    "                    df['Ethnicity*'],\n",
    "                    df['Race*'],\n",
    "                    df['Race Specify'],\n",
    "                    df['Description'],\n",
    "                    df['Sex at Birth*'],\n",
    "                    df['Age Event'],\n",
    "                    df['Subject Phenotype'],\n",
    "                    df['Study Location*'],\n",
    "                    df['Assessment Name'],\n",
    "                    df['Measured Behavioral or Psychological Factor*'],\n",
    "                    df['Measured Social Factor*'],\n",
    "                    df['SARS-CoV-2 Symptoms*'],\n",
    "                    df['Assessment_Clinical  and Demographic Data Provenance'],\n",
    "                    df['Assessment_Demographic Data Types Collected'],\n",
    "                    df['SARS-CoV2 History*'],\n",
    "                    df['SARS-CoV-2 Vaccine Type*'],\n",
    "                    df['COVID-19 Disease Severity*'],\n",
    "                    df['Post COVID-19 Symptoms'],\n",
    "                    df['COVID-19 Complications']\n",
    "                    )\n",
    "\n",
    "        elif sub_section == 'Subject Type: model organism':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            SUBJECT_ORGANISM = seroClass.subject_type_mode_organism(\n",
    "                df['Arm ID'],\n",
    "                df['Arm Name'],\n",
    "                df['Study Population Description'],\n",
    "                df['Arm Type'],\n",
    "                df['Species'],\n",
    "                df['Biosample Type'],\n",
    "                df['Strain Characteristics'],\n",
    "                df['Sex at Birth*'],\n",
    "                df['Age Event'],\n",
    "                df['Subject Phenotype'],\n",
    "                df['Study Location*'],\n",
    "                df['SARS-CoV2 History*'],\n",
    "                df['SARS-CoV-2 Vaccine Type*'],\n",
    "                df['COVID-19 Disease Severity*'],\n",
    "                df['Post COVID-19 Symptoms'],\n",
    "                df['COVID-19 Complications']\n",
    "                )\n",
    "        \n",
    "        elif sub_section == 'planned_visit':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            PLANNED_VISIT = seroClass.planned_visit(\n",
    "                df['Visit ID'],\n",
    "                df['Visit Name'],\n",
    "                df['Visit Order Number'],\n",
    "                df['Visit Min Start Day'],\n",
    "                df['Visit Max Start Day'],\n",
    "                df['Visit Start Rule']                                \n",
    "        )\n",
    "        \n",
    "        elif sub_section == 'Experiment Samples':\n",
    "            sys.exit(\"ERROR:: Incorrect Template format. Need to follow v1.2.3\")\n",
    "        #     FileExistsError\n",
    "        #     df = seroFxn.edit_df(df)\n",
    "\n",
    "        #     EXPERIMENT_SAMPLES = seroClass.study_experiment_samples(\n",
    "        #         df['Associated Arm ID'],\n",
    "        #         df['Associated Planned Visit ID'],\n",
    "        #         df['Expt Sample User Defined ID'],\n",
    "        #         df['Biospecimen Type*'],\n",
    "        #         df['Biospecimen Collection Point*']                             \n",
    "        # )\n",
    "        \n",
    "        elif sub_section == 'Experiments':\n",
    "            df = seroFxn.edit_df(df)\n",
    "\n",
    "            EXPERIMENTS = seroClass.experiments(\n",
    "                df['Associated Arm ID(s)'],\n",
    "                df['Associated First Planned Visit ID'],\n",
    "                df['Assay Type'],\n",
    "                df['Experiment Name'],\n",
    "                df['Experiment Results File Name'],\n",
    "                df['Biospecimen Type*'],\n",
    "                df['Biospecimen Collection Point'], \n",
    "                df['SARS-CoV-2 Antigen*'],\n",
    "                df['Assay Use'],\n",
    "                df['Manufacturer'],\n",
    "                df['Catalog #'],\n",
    "                df['Virus Target'],\n",
    "                df['Antibody Isotype*'],\n",
    "                df['Reporting Units'],\n",
    "                df['Assay Reporting Format']\n",
    "        )\n",
    "            \n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(sub_section, ': does not exist')\n",
    "\n",
    "\n",
    "\n",
    "    # # Sending back to ImmPort Template #\n",
    "\n",
    "\n",
    "\n",
    "    ImmPortClassNames = ['study', 'study_categorization', 'study_2_condition_or_disease',\n",
    "                   'arm_or_cohort','study_personnel', 'planned_visit', 'inclusion_exclusion',\n",
    "                   'study_2_protocol', 'study_file', 'study_link', 'study_pubmed'] \n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "\n",
    "\n",
    "    shutil.copy(PATH_basic_stdy_template, PATH_pmid_basic_stdy_template)\n",
    "    basic_stdy_template = load_workbook(PATH_pmid_basic_stdy_template)\n",
    "    bst_ws = basic_stdy_template['basic_study_design.txt']\n",
    "\n",
    "    se = seroFxn.get_sections(bst_ws, ImmPortClassNames)\n",
    "\n",
    "    #########################################\n",
    "    ######### Basic Study Template ##########\n",
    "    #########################################\n",
    "    vaccine_name = []\n",
    "    # print(\"*****\",SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type)\n",
    "\n",
    "    if SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type.any() and SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type.any():\n",
    "        \n",
    "        vaccine_name, vaccine_type = seroFxn.get_vaccine(set(list(SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type) + list(SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type)),\n",
    "                        clean_other)\n",
    "        \n",
    "        \n",
    "    elif SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type.any():\n",
    "        \n",
    "        vaccine_name, vaccine_type = seroFxn.get_vaccine(set(list(SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type)),\n",
    "                        clean_other)\n",
    "                                \n",
    "    elif SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type.any():\n",
    "        \n",
    "        vaccine_name, vaccine_type = seroFxn.get_vaccine(set(list(SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type)),\n",
    "                        clean_other)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        vaccine_name = []\n",
    "\n",
    "    # print(bool(vaccine_name), vaccine_name)\n",
    "    if len(vaccine_name):\n",
    "        vaccine_name = list(set([x.strip() for x in vaccine_name]))\n",
    "\n",
    "    if SUBJECT_HUMAN and SUBJECT_ORGANISM:\n",
    "#         print('Both human and model organism are used')\n",
    "        usr_id = list(SUBJECT_HUMAN.User_Defined_ID) + list(SUBJECT_ORGANISM.User_Defined_ID)\n",
    "        name = list(SUBJECT_HUMAN.Name) + list(SUBJECT_ORGANISM.Name)\n",
    "        description = list(SUBJECT_HUMAN.Description) + list(SUBJECT_ORGANISM.Description)\n",
    "        type_report = list(SUBJECT_HUMAN.Type_Reported) + list(SUBJECT_ORGANISM.Type_Reported)\n",
    "        \n",
    "        if set(SUBJECT_HUMAN.User_Defined_ID).intersection(SUBJECT_ORGANISM.User_Defined_ID):\n",
    "            print(\"\\n*** ERROR: Cannot have same User Defined ID's for AOCs:\")\n",
    "#             print(set(SUBJECT_HUMAN.User_Defined_ID).intersection(SUBJECT_ORGANISM.User_Defined_ID))\n",
    "            \n",
    "    if SUBJECT_HUMAN and not SUBJECT_ORGANISM:\n",
    "#         print('Only human is used')\n",
    "        usr_id = list(SUBJECT_HUMAN.User_Defined_ID)\n",
    "        name = list(SUBJECT_HUMAN.Name)\n",
    "        description = list(SUBJECT_HUMAN.Description)\n",
    "        type_report = list(SUBJECT_HUMAN.Type_Reported)\n",
    "        \n",
    "    if SUBJECT_ORGANISM and not SUBJECT_HUMAN:\n",
    "#         print('Only organism is used')\n",
    "        usr_id = list(SUBJECT_ORGANISM.User_Defined_ID)\n",
    "        name = list(SUBJECT_ORGANISM.Name)\n",
    "        description = list(SUBJECT_ORGANISM.Description)\n",
    "        type_report = list(SUBJECT_ORGANISM.Type_Reported)\n",
    "\n",
    "\n",
    "\n",
    "    temp_wb = Workbook()\n",
    "    temp_ws = temp_wb.active\n",
    "\n",
    "    #making a temp workbook to store each section. This will be turned into df\n",
    "\n",
    "    # This is the first part of the df\n",
    "    for i in bst_ws.iter_rows(values_only = True,\n",
    "                              max_row = se[2]+1):\n",
    "        temp_ws.append(i)\n",
    "        \n",
    "    # Starting at Arm or Cohort  \n",
    "    # print(usr_id, name, description, type_report)\n",
    "    AOC = seroClass.arm_or_cohort(\n",
    "        list(filter(None, usr_id)),\n",
    "        list(filter(None, name)),\n",
    "        list(filter(None, description)),\n",
    "        list(filter(None, type_report))\n",
    "    )\n",
    "\n",
    "    # temp_ws.append(['User Defined ID', 'Name','Description','Type Reported'])\n",
    "    seroFxn.add_df(temp_ws, AOC)\n",
    "\n",
    "    seroFxn.add_df(temp_ws, STUDY_PERSONNEL)\n",
    "\n",
    "    # Checking to see if assessment is used. If it is, then we will add another planned visit ID to \n",
    "    # The planned visit section \n",
    "    if SUBJECT_HUMAN.Assessment_Name.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV2_History.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV_2_Symptoms.any() or \\\n",
    "    SUBJECT_HUMAN.Measured_Social_Factor.any() or \\\n",
    "    SUBJECT_HUMAN.Measured_Behavioral_or_Psychological_Factor.any() or \\\n",
    "    SUBJECT_HUMAN.Assessment_Demographic_Data_Types_Collected.any() or \\\n",
    "    SUBJECT_HUMAN.Assessment_Clinical_and_Demographic_Data_Provenance.any():\n",
    "\n",
    "        add_index = len(PLANNED_VISIT.Name) + 1\n",
    "\n",
    "        PLANNED_VISIT.User_Defined_ID[add_index] = f'PMID{PMID}_assessment_recorded_pv'\n",
    "        PLANNED_VISIT.Name[add_index] = 'Visit where an assessment is recorded'\n",
    "        PLANNED_VISIT.Order_Number[add_index] = PLANNED_VISIT.Order_Number[add_index-1] + 1\n",
    "        PLANNED_VISIT.Min_Start_Day[add_index] = 0\n",
    "        PLANNED_VISIT.Max_Start_Day[add_index] = ''\n",
    "        PLANNED_VISIT.Start_Rule[add_index] = ''\n",
    "\n",
    "    seroFxn.add_df(temp_ws, PLANNED_VISIT)\n",
    "    seroFxn.add_df(temp_ws, INCLUSION_EXCLUSION)\n",
    "\n",
    "    # # Add protocol\n",
    "    temp_ws.append([])\n",
    "    temp_ws.append([PROTOCOLS.ImmPortNAME])\n",
    "    temp_ws.append(['Protocol ID', PROTOCOLS.Protocol_Name[1]])\n",
    "\n",
    "    seroFxn.add_df(temp_ws, STUDY_FILE)\n",
    "    seroFxn.add_df(temp_ws, STUDY_LINK)\n",
    "\n",
    "    seroFxn.add_df(temp_ws, STUDY_PUBMED)\n",
    "\n",
    "\n",
    "    # #### Filling in Study Info Sections \n",
    "\n",
    "\n",
    "\n",
    "    registryToImmportDict = pd.read_csv(registryToImmportDict_file, \n",
    "                                        header=None, \n",
    "                                        index_col=0, \n",
    "                                        squeeze=True).to_dict()\n",
    "    # registryToImmportDict\n",
    "    registryDict = {**vars(STUDY),\n",
    "                    **vars(STUDY_CATEGORIZATION),\n",
    "                    **vars(STUDY_DESIGN),\n",
    "                    **vars(STUDY_DETAILS),\n",
    "                    **vars(STUDY_PUBMED),\n",
    "                    **vars(COD)}\n",
    "\n",
    "    registryDict['SARS-CoV-2_Vaccine_Type'] = ['N/A']\n",
    "\n",
    "    if len([x for x in vaccine_name if x not in VARS_TO_CLEAN]) != 0:\n",
    "            registryDict['SARS-CoV-2_Vaccine_Type'] = [x for x in vaccine_name if x not in VARS_TO_CLEAN]\n",
    "\n",
    "\n",
    "            registryDict['SARS-CoV-2_Vaccine_Type'] = list(set((' | '.join(registryDict['SARS-CoV-2_Vaccine_Type'])).split(' | ')))\n",
    "\n",
    "\n",
    "#             print('########',\"\\n\",registryDict['SARS-CoV-2_Vaccine_Type'])\n",
    "\n",
    "    # Looping through ImmPort Template to get the correct order of the 'study' section\n",
    "    for se_number in range(se[0],se[3]):    \n",
    "     \n",
    "        if temp_ws[\"A\"][se_number].value != None and registryToImmportDict.get(temp_ws[\"A\"][se_number].value) != None:\n",
    "            \n",
    "            # Using a mapping key + using info in our classes to map the data\n",
    "            reg_key = registryToImmportDict.get(temp_ws[\"A\"][se_number].value).strip().replace(' ',\"_\").replace('*',\"\")\n",
    "            try:\n",
    "                # If input is a list, we will turn it into a string (since it cant be a list)\n",
    "                if type(registryDict.get(reg_key)) == list:\n",
    "                    temp_ws[\"B\"][se_number].value = ', '.join(registryDict.get(reg_key))\n",
    "                else:\n",
    "                    temp_ws[\"B\"][se_number].value = registryDict.get(reg_key)\n",
    "\n",
    "            except:\n",
    "                print(f\"{reg_key} did not work\")\n",
    "                \n",
    "\n",
    "\n",
    "    bsd = pd.DataFrame(temp_ws.values).replace({None: '', 'None': ''})\n",
    "    # bsd.to_excel(os.path.join(OUT_DIR, f'PMID{PMID}_study.xlsx'), index=False, header = False)\n",
    "    if TFBASIC:\n",
    "        bsd.to_csv(os.path.join(OUT_DIR,f'{BASIC_STUDY_TEMPLATE}.txt'),\n",
    "               header = False,\n",
    "               index = False,\n",
    "               sep = '\\t')\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ############## Protocol #################\n",
    "    #########################################\n",
    "\n",
    "    #Load Protocol\n",
    "    protocol_ws = load_workbook(PATH_protocols)['protocols.txt']\n",
    "    protocol_ws = seroFxn.remove_excess(protocol_ws)\n",
    "    seroFxn.add_df(protocol_ws, PROTOCOLS, add_header = False, stagger = 1)\n",
    "\n",
    "\n",
    "\n",
    "    protocol_df = pd.DataFrame(protocol_ws.values).replace({None: '', 'None': ''})\n",
    "    if TFPROTOCOL:\n",
    "        protocol_df.to_csv(os.path.join(OUT_DIR,f'{PROTOCOL_TEMPLATE}.txt'),\n",
    "                       header = False, \n",
    "                       index = False,\n",
    "                       sep = '\\t')\n",
    "#     try:\n",
    "#         shutil.copy(os.path.join(BASE_DIR,'templated_data', f'{PROTOCOLS.Protocol_Name[1]}.txt'),\n",
    "#                     os.path.join(OUT_DIR,f'{PROTOCOLS.Protocol_Name[1]}.txt'))\n",
    "#     except:\n",
    "#         print(f'** File:: {PROTOCOLS.Protocol_Name[1]}.txt does not exist **')\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ##########  EXPERIMENT SAMPLE   #########\n",
    "    #########################################\n",
    "    '''\n",
    "    # biosample should depend on the Planned Visit \n",
    "    # if the planned visit is the same, then the biosample id is the same. \n",
    "\n",
    "    # Experiment ID should depend in the Assay Type. All Assay types should be the same experimmnet ID\n",
    "\n",
    "    # Experiment Sample ID should be unique for each case? \n",
    "\n",
    "    # Reagent ID should either be no_reagents (if not serology) or the Serology reagent ID \n",
    "\n",
    "    # Treatment ID should be \"no_sars-cov-2_treatments\"\n",
    "\n",
    "    # Result File Name: resultsNotCurated.txt => pointerToExperimentalData.txt\n",
    "\n",
    "    # StudyTimeCollected should link back to the planned_visit.User_Defined_ID + planned_visit.Min_Start_Day\n",
    "    '''\n",
    "    reagentID = []\n",
    "\n",
    "    if  EXPERIMENTS:\n",
    "        # creating a map of the assay types to the SeroNet descriptors\n",
    "        reg_description = pd.read_excel(os.path.join('.','dictionary',EVS_DICT), sheet_name = EVS_sheet)\n",
    "        descriptions = dict(zip(reg_description['NCIt PT'], reg_description['NCIt Def']))\n",
    "        \n",
    "        #dictionary created for visit ID and min day\n",
    "        studyTime = dict(zip(PLANNED_VISIT.User_Defined_ID, PLANNED_VISIT.Min_Start_Day))\n",
    "\n",
    "        total_len = 0\n",
    "        biosampleID = []\n",
    "        experimentID = []\n",
    "        subjectID = []\n",
    "        plannedVisitID = []\n",
    "        bioSampleType = []\n",
    "        studyTimeCollected = []\n",
    "        experimentName = []\n",
    "        experimentReportingFormat = [] \n",
    "        bioSampleCollectPoint = []\n",
    "        expSample = []\n",
    "        empty = []\n",
    "\n",
    "        biosampleDict = {}\n",
    "        dictiter = 0\n",
    "\n",
    "        for i in range(len(EXPERIMENTS.Assay_Type)):\n",
    "            \n",
    "            arms = EXPERIMENTS.Associated_Arm_ID[i+1].split(\" | \")\n",
    "            assay = EXPERIMENTS.Assay_Type[i+1].split(\" | \") #this should always be 1\n",
    "            sample = EXPERIMENTS.Biospecimen_Type[i+1].split(\" | \")\n",
    "            pvID = EXPERIMENTS.Associated_Planned_Visit_ID[i+1].split(\" | \")\n",
    "\n",
    "            #creating a minidictionary to match the biosample IDs correctly \n",
    "            for biosample in sample:\n",
    "                if biosample not in biosampleDict.keys():\n",
    "                    biosampleDict[biosample] = f'PMID{PMID}_biosampleID-0{dictiter+1}'\n",
    "                    dictiter += 1\n",
    "\n",
    "\n",
    "            total_len= len(arms)*len(sample)*len(pvID) #possible combinations \n",
    "#             print(total_len)\n",
    "            \n",
    "            # biosampleID += [f'PMID{PMID}_biosampleID-0{i+1}']*total_len\n",
    "            experimentID += [f'PMID{PMID}_experimentID-0{i+1}']*total_len\n",
    "            experimentReportingFormat += [EXPERIMENTS.Reporting_Format[i+1]]*total_len\n",
    "\n",
    "\n",
    "            experimentName += [EXPERIMENTS.Assay_Type[i+1]]*int(total_len/len(assay))\n",
    "            bioSampleCollectPoint += [EXPERIMENTS.Biospecimen_Collection_Point[i+1]]*total_len\n",
    "            \n",
    "            # Only with 2 versions\n",
    "            # if EXPERIMENTS.SARS_CoV_2_Antigen[i+1] not in clean_other:\n",
    "            #     reagentID += [f'PMID{PMID}_reagentID-0{i+1}']*subLen\n",
    "            # else:\n",
    "            #     reagentID += ['no_reagents']*subLen\n",
    "            \n",
    "            # if len(arms) > 1 and len(sample) > 1:\n",
    "            #     total_arms = arms*len(sample)\n",
    "            #     total_sample = sample*len(arms)\n",
    "                \n",
    "            # elif len(arms) > 1 and len(sample) == 1:\n",
    "            #     total_arms = arms\n",
    "            #     total_sample = sample*len(arms)\n",
    "                \n",
    "            # elif len(arms) == 1 and len(sample) > 1:\n",
    "            #     total_arms = arms*len(sample)\n",
    "            #     total_sample = sample\n",
    "            # else:\n",
    "            #     total_arms = arms\n",
    "            #     total_sample = sample\n",
    "            \n",
    "            # The idea behind sorting would be to create a unifrom distribution of total arms and samples \n",
    "            # for the input we get. Ie. \n",
    "            # 1 2 3 1 2 3 1 2 3 [arms] (unsorted)\n",
    "            # a b c a b c a b c [samples] (unsorted)\n",
    "\n",
    "            # 1 2 3 1 2 3 1 2 3 [arms] (unsorted)\n",
    "            # a a a b b b c c c [samples] (sorted) -- giving all permutations \n",
    "\n",
    "            # BUT, now I need to add multiple Planned Visit IDs ....\n",
    "            # --- logic easy (should have 3)\n",
    "            # 1 [arm]\n",
    "            # 1 [sample]\n",
    "            # 1 2 3 [planned visit IDs]\n",
    "\n",
    "            # 1 [arm]                1 [arm]                1 [arm]        \n",
    "            # 1 [sample]             1 [sample]             1 [sample]\n",
    "            # 1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]\n",
    "\n",
    "            # --- logic harder (should have 6)\n",
    "            # 1 2 [arm]\n",
    "            # 1 [sample]\n",
    "            # 1 2 3 [planned visit IDs]\n",
    "\n",
    "            # 1 [arm]                1 [arm]                1 [arm]                2 [arm]                2 [arm]                2 [arm]       \n",
    "            # 1 [sample]             1 [sample]             1 [sample]             1 [sample]             1 [sample]             1 [sample]\n",
    "            # 1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]  1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]\n",
    "\n",
    "\n",
    "            # --- logic hardest (should have 12)\n",
    "            # 1 2 [arm]\n",
    "            # 1 2 [sample]\n",
    "            # 1 2 3 [planned visit IDs]\n",
    "\n",
    "            # 1 [arm]                1 [arm]                1 [arm]                2 [arm]                2 [arm]                2 [arm]       \n",
    "            # 1 [sample]             1 [sample]             1 [sample]             1 [sample]             1 [sample]             1 [sample]\n",
    "            # 1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]  1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]\n",
    "\n",
    "            # 1 [arm]                1 [arm]                1 [arm]                2 [arm]                2 [arm]                2 [arm]       \n",
    "            # 2 [sample]             2 [sample]             2 [sample]             2 [sample]             2 [sample]             2 [sample]\n",
    "            # 1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]  1 [planned visit IDs]  2 [planned visit IDs]  3 [planned visit IDs]\n",
    "\n",
    "            # seems like I can keep the same logic. It should be:\n",
    "            # 1 field times the other field, and then there is one filed that is exluded \n",
    "#             print(EXPERIMENTS.SARS_CoV_2_Antigen[i+1] == EXPERIMENTS.SARS_CoV_2_Antigen[i+1].strip().lower())\n",
    "# WEWORK\n",
    "#             if EXPERIMENTS.SARS_CoV_2_Antigen[i+1] not in clean_other:\n",
    "# #                 print(EXPERIMENTS.SARS_CoV_2_Antigen[i+1])\n",
    "#                 if EXPERIMENTS.SARS_CoV_2_Antigen[i+1].strip() not in clean_other:\n",
    "#                     reagentID += [f'PMID{PMID}_reagentID-0{i+1}']*total_len\n",
    "                    \n",
    "#                 else:\n",
    "#                     reagentID += [f'PMID{PMID}_reagents_not_curated']*total_len\n",
    "#             else:\n",
    "#                 reagentID += [f'PMID{PMID}_reagents_not_curated']*total_len\n",
    "            \n",
    "            if EXPERIMENTS.SARS_CoV_2_Antigen[i+1] not in clean_other:\n",
    "                reagentID += [f'PMID{PMID}_reagentID-0{i+1}']*total_len\n",
    "            else:\n",
    "                reagentID += [f'PMID{PMID}_reagents_not_curated']*total_len\n",
    "                \n",
    "            \n",
    "            \n",
    "            # print(arms)\n",
    "            # print(total_len)\n",
    "            # print(total_len/len(arms))\n",
    "            total_arms = arms*int(total_len/len(arms))\n",
    "            total_sample = sample*int(total_len/len(sample))\n",
    "            total_pvID = pvID*int(total_len/len(pvID)\n",
    "            )\n",
    "            if len(arms) > 1:\n",
    "                total_arms.sort()\n",
    "            elif len(sample) > 1:\n",
    "                total_sample.sort()\n",
    "            else:\n",
    "                total_pvID.sort()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            total_arms.sort()\n",
    "            \n",
    "            subjectID += total_arms # these are variable\n",
    "            bioSampleType += total_sample #these are variable\n",
    "            plannedVisitID += total_pvID\n",
    "            empty += ['']*total_len\n",
    "            \n",
    "        studyTimeCollected = [studyTime.get(visit_day.strip()) for visit_day in plannedVisitID]\n",
    "        fillLen=len(empty)\n",
    "\n",
    "        experimentSamples_df = pd.DataFrame({\n",
    "            'Column Name':empty,\n",
    "            'Expsample ID': [f'PMID{PMID}_expSample-0{n+1}' for n in range(fillLen)],\n",
    "            'Biosample ID': [biosampleDict.get(k) for k in bioSampleType],\n",
    "            'Experiment ID':experimentID,\n",
    "            'Reagent ID(s)':reagentID,\n",
    "            'Treatment ID(s)':[f'PMID{PMID}_treatment' for n in range(fillLen)],\n",
    "            'Result File Name':['pointerToExperimentalData.txt'] * fillLen,\n",
    "            'Expsample Name':empty,\n",
    "            'Expsample Description':[descriptions.get(k) for i, k in enumerate(experimentName)],\n",
    "            'Additional Result File Names':empty,\n",
    "            'Study ID':[STUDY.Study_Identifier]*fillLen,\n",
    "            'Protocol ID(s)':[PROTOCOLS.Protocol_ID[1]]*fillLen,\n",
    "            'Subject ID':subjectID,\n",
    "            'Planned Visit ID':plannedVisitID,\n",
    "            'Type':['Other']*fillLen,\n",
    "            'Subtype':bioSampleType,\n",
    "            'Biosample Name':empty, ## WHAT SHOULD THIS BE\n",
    "            'Biosample Description':empty,\n",
    "            'Study Time Collected':studyTimeCollected,\n",
    "            'Study Time Collected Unit':['Days']*fillLen,\n",
    "            'Study Time T0 Event':['Other']*fillLen,\n",
    "            'Study Time T0 Event Specify':bioSampleCollectPoint,\n",
    "            'Experiment Name':experimentName,\n",
    "            'Experiment Description':experimentReportingFormat, # This should be Experiment Name \n",
    "            'Measurement Technique':experimentName\n",
    "        })\n",
    "\n",
    "        expSample_ws = load_workbook(PATH_experiment_sample)['experimentSamples.Other.txt']\n",
    "        expSample_ws = seroFxn.remove_excess(expSample_ws)\n",
    "\n",
    "        # adding df to bottom of ws\n",
    "        seroFxn.add_df(expSample_ws, experimentSamples_df, add_header = False)\n",
    "        experimentSamples_df = pd.DataFrame(expSample_ws.values).replace({None: '', 'None': ''})\n",
    "\n",
    "        # saving df\n",
    "        if TFEXPERIMENTSAMPLE:\n",
    "            experimentSamples_df.to_csv(os.path.join(OUT_DIR,f'{EXPERIMENT_SAMPLES_TEMPLATE}.txt'),\n",
    "                           header = False, \n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "\n",
    "        ##########################\n",
    "        ###     TREATMENT      ###    #ASSUMPTION\n",
    "        ##########################\n",
    "        # only created if experiment samples are made\n",
    "        empty = ['']\n",
    "        TREATMENT_df = pd.DataFrame({\n",
    "            'Column Name': empty,\n",
    "            'User Defined ID': f'PMID{PMID}_treatment',\n",
    "            'Name': 'SARs CoV-2 Related Treatments',\n",
    "            'Use Treatment?': 'no',\n",
    "            'Amount Value': empty,\n",
    "            'Amount Unit': empty,\n",
    "            'Duration Value': empty,\n",
    "            'Duration Unit': empty,\n",
    "            'Temperature Value': empty,\n",
    "            'Temperature Unit': empty,\n",
    "            'Comments': empty\n",
    "        })\n",
    "\n",
    "        treatment_ws = load_workbook(PATH_treatment)['treatments.txt']\n",
    "        treatment_ws = seroFxn.remove_excess(treatment_ws)\n",
    "\n",
    "        # adding df to bottom of ws\n",
    "        seroFxn.add_df(treatment_ws, TREATMENT_df, add_header = False)\n",
    "        TREATMENT_df = pd.DataFrame(treatment_ws.values).replace({None: '', 'None': ''})\n",
    "\n",
    "        if TFTREATMENT:\n",
    "            TREATMENT_df.to_csv(os.path.join(OUT_DIR,f'{TREATMENT_TEMPALTE}.txt'),\n",
    "                           header = False, \n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "\n",
    "    #########################################\n",
    "    #############   REAGENT   ###############\n",
    "    #########################################\n",
    "# wework\n",
    "    if reagentID:\n",
    "        ID = []\n",
    "        Name = []\n",
    "        Description = []\n",
    "        Manufacturer = []\n",
    "        Catalog = []\n",
    "\n",
    "        counter = 0\n",
    "        # picking out the Indexs that contain data \n",
    "        '''\n",
    "            if it is not on the list, we will use normal naming conventions\n",
    "            ID convention and then fill in the rest with Reagents not curated. \n",
    "        '''\n",
    "#         for i, k in enumerate(EXPERIMENTS.SARS_CoV_2_Antigen):\n",
    "            \n",
    "#             if k in clean_other and counter == 0:\n",
    "#                 ID.append(f'PMID{PMID}_reagents_not_curated')\n",
    "#                 Name.append(f'Reagents not curated')\n",
    "#                 Description.append('Reagents not curated for this experiment')\n",
    "#                 Manufacturer.append('na')\n",
    "#                 Catalog.append('na')\n",
    "#                 counter += 1\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     lower_k = k.lower().strip()\n",
    "#                     if lower_k not in clean_other: \n",
    "#                         ID.append(f'PMID{PMID}_reagentID-0{i+1}')\n",
    "#                         Name.append(EXPERIMENTS.SARS_CoV_2_Antigen[i+1])\n",
    "#                         Description.append(EXPERIMENTS.Assay_Use[i+1])\n",
    "#                         Manufacturer.append(EXPERIMENTS.Manufacturer[i+1])\n",
    "#                         Catalog.append(EXPERIMENTS.Catalog[i+1])\n",
    "#                     else:\n",
    "#                         ID.append(f'PMID{PMID}_reagentID-0{i+1}')\n",
    "#                         Name.append(f'Reagents not curated')\n",
    "#                         Description.append('Reagents not curated for this experiment')\n",
    "#                         Manufacturer.append('na')\n",
    "#                         Catalog.append('na')\n",
    "#                 except:\n",
    "#                     if k not in clean_other:\n",
    "#                         ID.append(f'PMID{PMID}_reagentID-0{i+1}')\n",
    "#                         Name.append(EXPERIMENTS.SARS_CoV_2_Antigen[i+1])\n",
    "#                         Description.append(EXPERIMENTS.Assay_Use[i+1])\n",
    "#                         Manufacturer.append(EXPERIMENTS.Manufacturer[i+1])\n",
    "#                         Catalog.append(EXPERIMENTS.Catalog[i+1])\n",
    "\n",
    "        for i, k in enumerate(EXPERIMENTS.SARS_CoV_2_Antigen):\n",
    "            if k not in clean_other:\n",
    "\n",
    "                       \n",
    "#         # picking out the Indexs that contain data \n",
    "#         for i, k in enumerate(EXPERIMENTS.SARS_CoV_2_Antigen):\n",
    "#             if k not in clean_other:\n",
    "#                 ID.append(f'PMID{PMID}_reagentID-0{i+1}')\n",
    "#                 Name.append(EXPERIMENTS.SARS_CoV_2_Antigen[i+1])\n",
    "#                 Description.append(EXPERIMENTS.Assay_Use[i+1])\n",
    "#                 Manufacturer.append(EXPERIMENTS.Manufacturer[i+1])\n",
    "#                 Catalog.append(EXPERIMENTS.Catalog[i+1])\n",
    "        \n",
    "#             elif counter == 0:\n",
    "#                 ID.append(f'PMID{PMID}_reagents_not_curated')\n",
    "#                 Name.append(f'Reagents not curated')\n",
    "#                 Description.append('Reagents not curated for this experiment')\n",
    "#                 Manufacturer.append('na')\n",
    "#                 Catalog.append('na')\n",
    "#                 counter += 1\n",
    "                    \n",
    "\n",
    "\n",
    "        if len(ID) > 0: \n",
    "\n",
    "            empty = [''] * len(ID)\n",
    "\n",
    "            reagent_df = pd.DataFrame({\n",
    "                'Column Name': empty,\n",
    "                'User Defined ID': ID,\n",
    "                'Name': Name,\n",
    "                'Description': Description,\n",
    "                'Manufacturer': Manufacturer,\n",
    "                'Catalog Number': Catalog,\n",
    "                'Weblink': empty,\n",
    "                'Contact': empty\n",
    "\n",
    "            })\n",
    "\n",
    "            # loading experiment template and removing excess rows and columns\n",
    "            reagent_ws = load_workbook(PATH_reagent)['reagents.Other.txt']\n",
    "            reagent_ws = seroFxn.remove_excess(reagent_ws)\n",
    "            if TFREAGENT:\n",
    "                tempereere = reagent_df\n",
    "                # adding df to bottom of ws\n",
    "                seroFxn.add_df(reagent_ws, reagent_df, add_header = False)\n",
    "                reagent_df = pd.DataFrame(reagent_ws.values).replace({None: '', 'None': ''})\n",
    "\n",
    "                # saving df\n",
    "                reagent_df.to_csv(os.path.join(OUT_DIR,f'{REAGENT_TEMPLATE}.txt'),\n",
    "                               header = False, \n",
    "                               index = False,\n",
    "                               sep = '\\t')\n",
    "                return(tempereere)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    ###         SUBJECT: HUMAN       ########\n",
    "    #########################################\n",
    "    # - if human, use human\n",
    "    # - if animal, use animal sheet \n",
    "    # - use length as a predictor\n",
    "\n",
    "    HUMAN SHOULD BE FOR HUMAN CELLS LINES. DO NOT PUT IN ORGANISM\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if SUBJECT_HUMAN:\n",
    "        # race_specificty =[]\n",
    "        # for i in SUBJECT_HUMAN.Race: RACE OTHER\n",
    "        #     if i == 'Other':\n",
    "        #         race_specificty.append(\"Other\")\n",
    "        #     else:\n",
    "        #         race_specificty.append(\"\")\n",
    "\n",
    "\n",
    "        species = SUBJECT_HUMAN.User_Defined_ID\n",
    "        empty = ['']*len(species)\n",
    "\n",
    "        if SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type.any():\n",
    "            vaccine_name, vaccine_type = seroFxn.get_vaccine(SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type, VARS_TO_CLEAN)\n",
    "\n",
    "        else:\n",
    "            vaccine_name = empty\n",
    "            vaccine_type = empty\n",
    "\n",
    "        SUBJECT_human_df = pd.DataFrame({\n",
    "            'Column Name': empty,\n",
    "            'Subject ID': [f\"PMID{PMID}_human_subject-0{int(i+1)}\" for i in range(len(species))],\n",
    "            'Arm Or Cohort ID': SUBJECT_HUMAN.User_Defined_ID, #I feel like this needs to be defined\n",
    "            'Gender': SUBJECT_HUMAN.Sex_at_Birth, \n",
    "            'Min Subject Age': [STUDY_DETAILS.Minimum_Age]*len(species), # #ASSUMPTION - defualts to 0\n",
    "            'Max Subject Age': [STUDY_DETAILS.Maximum_Age]*len(species), # #ASSUMPTION - defaults to 89\n",
    "            'Age Unit': [STUDY_DETAILS.Age_Unit]*len(species),\n",
    "            'Age Event': SUBJECT_HUMAN.Age_Event, \n",
    "            'Age Event Specify': empty,\n",
    "            'Subject Phenotype': empty, \n",
    "            'Subject Location': SUBJECT_HUMAN.Study_Location,\n",
    "            'Ethnicity': SUBJECT_HUMAN.Ethnicity,\n",
    "            'Race': SUBJECT_HUMAN.Race, \n",
    "            'Race Specify': SUBJECT_HUMAN.Race_Specify,\n",
    "            'Description': empty, \n",
    "            'Result Separator Column': empty, \n",
    "            'Exposure Process Reported': ['unknown']*len(species) , #not sure \n",
    "            'Exposure Material Reported': vaccine_name, # change this\n",
    "            'Exposure Material ID': vaccine_type,\n",
    "            'Disease Reported': [COD.Reported_Health_Condition[0]]*len(species), # This was not correct\n",
    "            'Disease Ontology ID': empty,\n",
    "            'Disease Stage Reported': SUBJECT_HUMAN.COVID_19_Disease_Severity #CHANGE\n",
    "        })\n",
    "        \n",
    "        # loading experiment template and removing excess rows and columns\n",
    "        human_ws = load_workbook(PATH_subject_human)['subjectHumans.txt']\n",
    "        human_ws = seroFxn.remove_excess(human_ws)\n",
    "\n",
    "        # adding df to bottom of ws\n",
    "        seroFxn.add_df(human_ws, SUBJECT_human_df, add_header = False)\n",
    "        SUBJECT_human_df = pd.DataFrame(human_ws.values).replace({None: '', 'None': ''})\n",
    "\n",
    "    #     # saving df\n",
    "        if TFHUMAN:\n",
    "            SUBJECT_human_df.to_csv(os.path.join(OUT_DIR,f'{SUBJ_HUMAN_TEMPLATE}.txt'),\n",
    "                           header = False, \n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "\n",
    "    #     print(SUBJECT_human_df)\n",
    "#         print (\"SUBJECT: human data created\")\n",
    "    # else:\n",
    "    #     print('no human data')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    #####       SUBJECT: ORGANISM    ########\n",
    "    #########################################\n",
    "    For Syrain Hamster: https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?name=Syrian+hamsters \n",
    "\n",
    "    Use latin name -- or look at lk species\n",
    "    https://www.immport.org/shared/templateDocumentation?tab=2&table=lk_species\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if SUBJECT_ORGANISM:  # Not sure how this plays out. Might need to do a mock one. Will it be 1 subject per study?\n",
    "        species = SUBJECT_ORGANISM.User_Defined_ID\n",
    "        empty = ['']*len(species)\n",
    "\n",
    "        if SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type.any():\n",
    "            vaccine_name, vaccine_type = seroFxn.get_vaccine(SUBJECT_ORGANISM.SARS_CoV_2_Vaccine_Type, VARS_TO_CLEAN)\n",
    "\n",
    "        else:\n",
    "            vaccine_name = empty\n",
    "            vaccine_type = empty\n",
    "\n",
    "        # print (\"SUBJECT_organism data\")\n",
    "        SUBJECT_organism_df = pd.DataFrame({\n",
    "            'Column Name':empty,\n",
    "            'Subject ID': [f\"PMID{PMID}_organism_subject-0{int(i+1)}\" for i in range(len(species))], #SUBJECT_ORGANISM.User_Defined_ID, #\n",
    "            'Arm Or Cohort ID': SUBJECT_ORGANISM.User_Defined_ID, #I feel like this needs to be defined\n",
    "            'Gender': SUBJECT_ORGANISM.Sex_at_Birth,\n",
    "            'Min Subject Age': [STUDY_DETAILS.Minimum_Age]*len(species),\n",
    "            'Max Subject Age': [STUDY_DETAILS.Maximum_Age]*len(species),\n",
    "            'Age Unit': [STUDY_DETAILS.Age_Unit] * len(species),\n",
    "            'Age Event': SUBJECT_ORGANISM.Age_Event,\n",
    "            'Age Event Specify': empty,\n",
    "            'Subject Phenotype': empty, ## This does not exist\n",
    "            'Subject Location': SUBJECT_ORGANISM.Study_Location,\n",
    "            'Species': SUBJECT_ORGANISM.Species,\n",
    "            'Strain': SUBJECT_ORGANISM.Biosample_Types,\n",
    "            'Strain Characteristics': SUBJECT_ORGANISM.Strain_Characteristics,\n",
    "            'Result Separator Column': empty,\n",
    "            'Exposure Process Reported': ['unknown']*len(species),\n",
    "            'Exposure Material Reported': vaccine_name,\n",
    "            'Exposure Material ID': vaccine_type, \n",
    "            'Disease Reported': [COD.Reported_Health_Condition[0]]*len(species), # also maybe not...\n",
    "            'Disease Ontology ID': empty,\n",
    "            'Disease Stage Reported': SUBJECT_ORGANISM.COVID_19_Disease_Severity\n",
    "        })\n",
    "        \n",
    "            # loading experiment template and removing excess rows and columns\n",
    "        organism_ws = load_workbook(PATH_subject_organism)['subjectAnimals.txt']\n",
    "        organism_ws = seroFxn.remove_excess(organism_ws)\n",
    "\n",
    "        # adding df to bottom of ws\n",
    "        seroFxn.add_df(organism_ws, SUBJECT_organism_df, add_header = False)\n",
    "        SUBJECT_organism_df = pd.DataFrame(organism_ws.values).replace({None: '', 'None': ''})\n",
    "\n",
    "        # saving df\n",
    "        if TFORGANISM:\n",
    "            SUBJECT_organism_df.to_csv(os.path.join(OUT_DIR,f'{SUBJ_ORGANISM_TEMPLATE}.txt'),\n",
    "                           header = False, \n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "\n",
    "        SUBJECT_organism_df\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    #########################################\n",
    "    ######       ASSESSMENT        ##########\n",
    "    #########################################\n",
    "\n",
    "    # There will be 1 excel document produced per assesment. (wide format) <br>\n",
    "    #     - 1 subj with multiple panels -> seperate \n",
    "    #     - 1 panel with multiple subject -> 1 row per, long format\n",
    "    # assesment doc. need to be uploaded one at a time\n",
    "    # 1 subject per arm, seperated by row\n",
    "    # in each file, it is based off of the 'Name Reported [E]'\n",
    "    # Same Panel [E] per-file, but you can add on different components in a single file [L]\n",
    "    # new file per Panel\n",
    "\n",
    "    # if Assessment is used, we create a treatment template to link to the assessments\n",
    "\n",
    "    # print(SUBJECT_HUMAN.Assessment_Clinical_and_Demographic_Data_Provenance)\n",
    "\n",
    "    if SUBJECT_HUMAN.Assessment_Name.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV_2_Vaccine_Type.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV2_History.any() or \\\n",
    "    SUBJECT_HUMAN.SARS_CoV_2_Symptoms.any() or \\\n",
    "    SUBJECT_HUMAN.Measured_Social_Factor.any() or \\\n",
    "    SUBJECT_HUMAN.Measured_Behavioral_or_Psychological_Factor.any() or \\\n",
    "    SUBJECT_HUMAN.Assessment_Demographic_Data_Types_Collected.any() or \\\n",
    "    SUBJECT_HUMAN.Assessment_Clinical_and_Demographic_Data_Provenance.any():\n",
    "\n",
    "#         print(\"Assays Used\")\n",
    "\n",
    "        \n",
    "        \n",
    "        @dataclass\n",
    "        class sepAssessment:\n",
    "            user_ID: list = field(default_factory=list) \n",
    "            assessment_name: list = field(default_factory=list) \n",
    "            assessmet_type: list = field(default_factory=list) \n",
    "            status: list = field(default_factory=list)\n",
    "            assessment_component: list = field(default_factory=list) \n",
    "\n",
    "\n",
    "        def updateObject(obj,obj2,i,field):\n",
    "            obj.user_ID.append(obj2.User_Defined_ID[i])\n",
    "            obj.assessment_name.append(field) #Field\n",
    "            obj.assessmet_type.append(obj2.Assessment_Clinical_and_Demographic_Data_Provenance[i])\n",
    "            obj.status.append(obj2.Assessment_Demographic_Data_Types_Collected[i])\n",
    "            \n",
    "            if field == \"Measured Behavioral or Psychological Factor\":\n",
    "                obj.assessment_component.append(obj2.Measured_Behavioral_or_Psychological_Factor[i])\n",
    "            elif field == \"Measured Social Factor\":\n",
    "                obj.assessment_component.append(obj2.Measured_Social_Factor[i])\n",
    "            elif field == \"SARS CoV2 Symptoms\":\n",
    "                obj.assessment_component.append(obj2.SARS_CoV_2_Symptoms[i])\n",
    "            elif field == \"SARS CoV2 History\":\n",
    "                obj.assessment_component.append(obj2.SARS_CoV2_History[i])\n",
    "            else:\n",
    "                sys.exit(\"ERROR:: Undefined field for assessment component\")\n",
    "                \n",
    "            \n",
    "        def makeAssessmentDF(obj,obj2,PMIDs,field):\n",
    "            empty = ['']*len(obj.user_ID)\n",
    "            \n",
    "            ASSESSMENT_df = pd.DataFrame({\n",
    "                'Column Name': empty,\n",
    "                'Subject ID': obj.user_ID,  \n",
    "                'Assessment Panel ID': [f\"PMID{PMIDs}_assessment_{field}-0{int(i+1)}\" for i in range(len(obj.user_ID))],\n",
    "                'Study ID': [obj2.Study_Identifier]*len(obj.user_ID),\n",
    "                'Name Reported': obj.assessment_name,\n",
    "                'Assessment Type': obj.assessmet_type,\n",
    "                'Status': obj.status,\n",
    "                'CRF File Names': empty,\n",
    "                'Result Separator Column': empty,\n",
    "                'User Defined ID': [f\"PMID{PMIDs}_component_{field}-0{int(i+1)}\" for i in range(len(obj.user_ID))], # this is the component ID\n",
    "                'Planned Visit ID': [f'PMID{PMID}_assessment_recorded_pv']*len(obj.user_ID), #ASSUMPTION\n",
    "                'Name Reported ': obj.assessment_component,\n",
    "                'Study Day': ['0']*len(obj.user_ID), # Not sure, we dont capture study day \n",
    "                'Age At Onset Reported': empty,\n",
    "                'Age At Onset Unit Reported': empty,\n",
    "                'Is Clinically Significant': empty,\n",
    "                'Location Of Finding Reported': empty,\n",
    "                'Organ Or Body System Reported': empty,\n",
    "                'Result Value Reported': 'NA',\n",
    "                'Result Unit Reported': empty,\n",
    "                'Result Value Category': empty,\n",
    "                'Subject Position Reported': empty,\n",
    "                'Time Of Day': empty,\n",
    "                'Verbatim Question': empty,\n",
    "                'Who Is Assessed': empty\n",
    "            })\n",
    "            \n",
    "            assessment_ws = load_workbook(PATH_assessment)['assessments.txt']\n",
    "            assessment_ws = seroFxn.remove_excess(assessment_ws)\n",
    "\n",
    "            # adding df to bottom of ws\n",
    "            seroFxn.add_df(assessment_ws, ASSESSMENT_df, add_header = False)\n",
    "            ASSESSMENT_df = pd.DataFrame(assessment_ws.values).replace({None: '', 'None': ''})\n",
    "            \n",
    "            return ASSESSMENT_df\n",
    "            \n",
    "            \n",
    "        MBPF = sepAssessment()\n",
    "        MSF = sepAssessment()\n",
    "        SCS = sepAssessment()\n",
    "        SCH = sepAssessment()\n",
    "        \n",
    "        for n, subject in enumerate(SUBJECT_HUMAN.User_Defined_ID):\n",
    "            n += 1\n",
    "            \n",
    "            if SUBJECT_HUMAN.Measured_Behavioral_or_Psychological_Factor[n]:\n",
    "#                 print('Measured Behavioral or Psychological Factor') #MBPF\n",
    "                # updateObject(MBPF,SUBJECT_HUMAN,n, 'MBPF')\n",
    "                updateObject(MBPF,SUBJECT_HUMAN,n,'Measured Behavioral or Psychological Factor')\n",
    "                MBPF_df = makeAssessmentDF(SCS,STUDY,PMID,'MBPF')\n",
    "                if TFASSESSMENT:\n",
    "                    MBPF_df.to_csv(os.path.join(OUT_DIR,f'PMID{PMID}_panel_MBPF.txt'),\n",
    "                           header = False,\n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "                \n",
    "            if SUBJECT_HUMAN.Measured_Social_Factor[n]:\n",
    "#                 print('Measured_Social_Factor') #MSF\n",
    "                # updateObject(MSF,SUBJECT_HUMAN,n, 'MSF')\n",
    "                updateObject(MSF,SUBJECT_HUMAN,n, 'Measured Social Factor')\n",
    "                MSF_df = makeAssessmentDF(SCS,STUDY,PMID,'MSF')\n",
    "                if TFASSESSMENT:\n",
    "                    MSF_df.to_csv(os.path.join(OUT_DIR,f'PMID{PMID}_panel_MSF.txt'),\n",
    "                           header = False,\n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "                \n",
    "                \n",
    "            if SUBJECT_HUMAN.SARS_CoV_2_Symptoms[n]:\n",
    "#                 print('SARS_CoV_2_Symptoms') #SCS\n",
    "                # updateObject(SCS,SUBJECT_HUMAN,n,'SCS')\n",
    "                updateObject(SCS,SUBJECT_HUMAN,n,'SARS CoV2 Symptoms')\n",
    "                SCS_df = makeAssessmentDF(SCS,STUDY,PMID,'SCS')\n",
    "                if TFASSESSMENT:\n",
    "                    SCS_df.to_csv(os.path.join(OUT_DIR,f'PMID{PMID}_panel_SCS.txt'),\n",
    "                           header = False,\n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "\n",
    "            if SUBJECT_HUMAN.SARS_CoV2_History[n]:\n",
    "#                 print('SARS_CoV2_History') #SCH\n",
    "                # updateObject(SCH,SUBJECT_HUMAN,n,'SCH')\n",
    "                updateObject(SCH,SUBJECT_HUMAN,n,'SARS CoV2 History')\n",
    "                SCH_df = makeAssessmentDF(SCH,STUDY,PMID,'SCH')\n",
    "                if TFASSESSMENT:\n",
    "                    SCH_df.to_csv(os.path.join(OUT_DIR,f'PMID{PMID}_panel_SCH.txt'),\n",
    "                           header = False,\n",
    "                           index = False,\n",
    "                           sep = '\\t')\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                print(f'No assessments found for {subject}')\n",
    "\n",
    "    else:\n",
    "        print(\"No Human Subjects: assessments not recorded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9de3d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_ids = [\n",
    "    35764643, 33035201, 33065030, 33142304, 33160316, 33160316, 33169014, 33169014, 33276369, 33276369, 33408181, 33408181, 33440148, 33440148, 33472939, 33472939, 33478949, 33478949, 33479118, 33479118, 33521695, 33521695, 33571162, 33571162, 33602725, 33602725, 33622794, 33622794, 33666169, 33666169, 33704352, 33727353, 33727353, 33743211, 33743211, 33830946, 33830946, 33846272, 33846272, 33893169, 33961839, 33961839, 33993265, 33993265, 34001652, 34003112, 34003112, 34086877, 34086877, 34095338, 34095338, 34100011, 34100011, 34107529, 34130883, 34130883, 34145263, 34145263, 34151306, 34151306, 34161961, 34161961, 34230917, 34250512, 34260834, 34353890, 34353890, 34452006, 34452006, 34523968, 34652783, 34652783, 34687893, 34687893, 34696403, 34696403, 34730254, 34730254, 34759001, 34759001, 34794169, 34794169, 34802457, 34802457, 34835131, 34835131, 34877479, 34877479, 34910927, 34910927, 34921308, 34921308, 34937699, 34937699, 34952892, 34952892, 35013325, 35025672, 35040666, 35129576, 35132398, 35132398, 35143473, 35148837, 35289637, 35348368, 35427477, 35455241, 35504289, 35589681, 35764643\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2462a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass JSONEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "340cb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmed_ids = [34107529]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "015a91aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liualg/opt/anaconda3/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liualg/opt/anaconda3/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:221: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Human Subjects: assessments not recorded\n",
      "No assessments found for PMID34687893_human_subject-01\n",
      "No assessments found for PMID34687893_human_subject-02\n",
      "35427477\n",
      "No Human Subjects: assessments not recorded\n",
      "34952892\n",
      "No Human Subjects: assessments not recorded\n",
      "No Human Subjects: assessments not recorded\n",
      "34759001\n",
      "No Human Subjects: assessments not recorded\n"
     ]
    }
   ],
   "source": [
    "reagent = []\n",
    "# for pubmed_id in tqdm(set(pubmed_ids)):\n",
    "for pubmed_id in set(pubmed_ids):\n",
    "    pubmed_id = str(pubmed_id)\n",
    "    \n",
    "#     to_json.create_json(pubmed_id)\n",
    "    try:\n",
    "        reagent.append(create_full(pubmed_id))\n",
    "    except:\n",
    "        print(pubmed_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bf9d7",
   "metadata": {},
   "source": [
    "35427477 = 'Assessment_Clinical  and Demographic Data Provenance*' vs 'Assessment_Clinical  and Demographic Data Provenance'<br>\n",
    "34952892\n",
    "34759001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da2574f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat(reagent, ignore_index=True)\n",
    "# temp.to_csv(\"./DR46/DR46-reagent_update.csv\")\n",
    "# temp.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9201e225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>User Defined ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Catalog Number</th>\n",
       "      <th>Weblink</th>\n",
       "      <th>Contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-01</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-02</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-03</td>\n",
       "      <td>Full Length Spike Trimer | Receptor Binding Do...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-04</td>\n",
       "      <td>Full Length Spike Trimer | Receptor Binding Do...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-05</td>\n",
       "      <td>Full Length Spike Trimer | Receptor Binding Do...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td></td>\n",
       "      <td>PMID34145263_reagentID-06</td>\n",
       "      <td>Full Length Spike Trimer | Receptor Binding Do...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column Name            User Defined ID  \\\n",
       "134              PMID34145263_reagentID-01   \n",
       "135              PMID34145263_reagentID-02   \n",
       "136              PMID34145263_reagentID-03   \n",
       "137              PMID34145263_reagentID-04   \n",
       "138              PMID34145263_reagentID-05   \n",
       "139              PMID34145263_reagentID-06   \n",
       "\n",
       "                                                  Name Description  \\\n",
       "134                                              n/a           n/a   \n",
       "135                                              n/a           n/a   \n",
       "136  Full Length Spike Trimer | Receptor Binding Do...         n/a   \n",
       "137  Full Length Spike Trimer | Receptor Binding Do...         n/a   \n",
       "138  Full Length Spike Trimer | Receptor Binding Do...         n/a   \n",
       "139  Full Length Spike Trimer | Receptor Binding Do...         n/a   \n",
       "\n",
       "                               Manufacturer Catalog Number Weblink Contact  \n",
       "134  components from multiple manufacturers            n/a                  \n",
       "135  components from multiple manufacturers            n/a                  \n",
       "136  components from multiple manufacturers            n/a                  \n",
       "137  components from multiple manufacturers            n/a                  \n",
       "138  components from multiple manufacturers            n/a                  \n",
       "139  components from multiple manufacturers            n/a                  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp[temp['User Defined ID'].str.contains('33961839')]\n",
    "temp[temp['User Defined ID'].str.contains('34145263')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d71670",
   "metadata": {},
   "source": [
    "### Adding 35427477, 34952892, 34759001 by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d266f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c4660671f393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35143473\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-3f7004badf77>\u001b[0m in \u001b[0;36mcreate_full\u001b[0;34m(PMID)\u001b[0m\n\u001b[1;32m    900\u001b[0m             '''\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_other\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m                 \u001b[0mID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'PMID{PMID}_reagentID-0{i+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0mName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Reagents not curated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "create_full(str(35143473))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fc5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
