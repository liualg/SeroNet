{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13a9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seronetDataclass as seroClass\n",
    "import seronetFunctions as seroFxn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aeb735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_base = \"~/Library/CloudStorage/Box-Box/SeroNet Public Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b69d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Line Number Locations in Excel File\n",
    "#\n",
    "STUDY_PUBMED = 13\n",
    "\n",
    "STUDY_IDENTIFIER = 16\n",
    "STUDY_NAME = 17\n",
    "PUBLICATION_TITLE = 18\n",
    "STUDY_OBJECTIVE = 19\n",
    "STUDY_DESCRIPTION = 20\n",
    "PRIMARY_INSTITUTION_NAME = 21\n",
    "\n",
    "STUDY_PERSONNEL = 25\n",
    "STUDY_FILE = 39\n",
    "STUDY_LINK = 45\n",
    "STUDY_CATEGORIZATION = 49\n",
    "RESEARCH_FOCUS = 50\n",
    "STUDY_TYPE = 51\n",
    "KEYWORDS = 52\n",
    "STUDY_DESIGN = 55\n",
    "CLINICAL_STUDY_DESIGN = 56\n",
    "IN_SILICO_MODEL_TYPE = 57\n",
    "PROTOCOLS = 60\n",
    "PROTOCOL_ID = 61\n",
    "PROTOCOL_FILE_NAME = 62\n",
    "PROTOCOL_NAME = 63\n",
    "PROTOCOL_DESCRIPTION = 64\n",
    "PROTOCOL_TYPE = 65\n",
    "CONDITION_OR_DISEASE = 68\n",
    "REPORTED_HEALTH_CONDITION = 69\n",
    "INTERVENTION_AGENT = 72\n",
    "SARS_COV_2_VACCINE_TYPE = 73\n",
    "STUDY_DETAILS = 76\n",
    "CLINICAL_OUTCOME_MEASURE = 77\n",
    "ENROLLMENT_START_DATE = 78\n",
    "ENROLLMENT_END_DATE = 79\n",
    "NUMBER_OF_STUDY_SUBJECTS = 80\n",
    "AGE_UNIT = 81\n",
    "MINIMUM_AGE = 82\n",
    "MAXIMUM_AGE = 83\n",
    "\n",
    "INCLUSION_EXCLUSION = 86\n",
    "INCLUSION_ID = 87\n",
    "INCLUSION_CRITERION = 88\n",
    "INCLUSION_CRITERION_CATEGORY = 89\n",
    "\n",
    "HUMAN_ARM_ID = 93\n",
    "HUMAN_ARM_NAME = 94\n",
    "HUMAN_STUDY_POPULATION_DESCRIPTION = 95\n",
    "HUMAN_ARM_TYPE = 96\n",
    "HUMAN_ETHNICITY = 97\n",
    "HUMAN_RACE = 98\n",
    "HUMAN_RACE_SPECIFY = 99\n",
    "HUMAN_DESCRIPTION = 100\n",
    "HUMAN_SEX_AT_BIRTH = 101\n",
    "HUMAN_AGE_EVENT = 102\n",
    "HUMAN_SUBJECT_PHENOTYPE = 103\n",
    "HUMAN_STUDY_LOCATION = 104\n",
    "HUMAN_ASSESSMENT_NAME = 105\n",
    "HUMAN_MEASURED_BEHAVIORAL_OR_PYSCHOLOGICAL_FACTOR = 106\n",
    "HUMAN_MEASURED_SOCIAL_FACTOR = 107\n",
    "HUMAN_SARS_COV_2_SYMPTOMS = 108\n",
    "HUMAN_ASSESSMENT_CLINICAL_AND_DEMOGRAPHIC_DATA_PROVENANCE = 109\n",
    "HUMAN_ASSESSMENT_DEMOGRAPHIC_DATA_TYPES_COLLECTED = 110\n",
    "HUMAN_SARS_COV_2_HISTORY = 111\n",
    "HUMAN_SARS_COV_2_VACCINE_TYPE = 112\n",
    "HUMAN_COVID_19_DISEASE_SEVERITY = 113\n",
    "HUMAN_POST_COVID_19_SYMPTOMS = 114\n",
    "HUMAN_COVID_19_COMPLICATIONS = 115\n",
    "\n",
    "MODEL_ARM_ID = 119\n",
    "MODEL_ARM_NAME = 120\n",
    "MODEL_STUDY_POPULATION_DESCRIPTION = 121\n",
    "MODEL_ARM_TYPE = 122\n",
    "MODEL_SPECIES = 123\n",
    "MODEL_BIOSAMPLE_TYPE = 124\n",
    "MODEL_STRAIN_CHARACTERISTICS = 125\n",
    "MODEL_SEX_AT_BIRTH = 126\n",
    "MODEL_AGE_EVENT = 127\n",
    "MODEL_SUBJECT_PHENOTYPE = 128\n",
    "MODEL_STUDY_LOCATION = 129\n",
    "MODEL_SARS_COV_2_HISTORY = 130\n",
    "MODEL_SARS_COV_2_VACCINE_TYPE = 131\n",
    "MODEL_COVID_19_DISEASE_SEVERITY = 132\n",
    "MODEL_POST_COVID_19_SYMPTOMS = 133\n",
    "MODEL_COVID_19_COMPLICATIONS = 134\n",
    "\n",
    "PLANNED_VISIT = 137\n",
    "VISIT_ID = 138\n",
    "VISIT_NAME = 139\n",
    "VISIT_ORDER_NUMBER = 140\n",
    "VISIT_MIN_START_DAY = 141\n",
    "VISIT_MAX_START_DAY = 142\n",
    "VISIT_START_RULE = 143\n",
    "\n",
    "EXPERIMENTS = 147\n",
    "ASSOCIATED_ARM_IDS = 148\n",
    "ASSOCIATED_FIRST_PLANNED_VISIT_ID = 149\n",
    "ASSAY_TYPE = 150\n",
    "EXPERIMENT_NAME = 151\n",
    "EXPERIMENT_RESULTS_FILE_NAME = 152\n",
    "BIOSPECIMEN_TYPE = 153\n",
    "BIOSPECIMEN_COLLECTION_POINT = 154\n",
    "SARS_COV_2_ANTIGEN = 155\n",
    "ASSAY_USE = 156\n",
    "MANUFACTURER = 157\n",
    "CATALOG_NUMBER = 158\n",
    "VIRUS_TARGET = 159\n",
    "ANTIBODY_ISOTYPE = 160\n",
    "REPORTING_UNITS = 161\n",
    "ASSAY_REPORTING_FORMAT = 162\n",
    "\n",
    "#\n",
    "# Remove characters or escape characters that corrupt JSON\n",
    "#\n",
    "def cleanData(s):\n",
    "    \"\"\"Removes characters in the input string that will corrupt the final JSON object\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    else:\n",
    "        if isinstance(s, str):\n",
    "            r1 = re.compile(\"\\n|\\t|\\r\")\n",
    "            r2 = re.compile('\"')\n",
    "            s = r1.sub(\" \", s)\n",
    "            s = r2.sub('\\\\\"', s)\n",
    "            s = s.strip()\n",
    "        elif isinstance(s, datetime):\n",
    "            s = s.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            pass\n",
    "        return s\n",
    "\n",
    "\n",
    "def parse_sv(df, line_number, index):\n",
    "    return list(df.loc[line_number])[index]\n",
    "\n",
    "\n",
    "def parse_clean_sv(df, line_number, index):\n",
    "    \"\"\"Cleans and returns data in a List\"\"\"\n",
    "    return cleanData(list(df.loc[line_number])[index])\n",
    "\n",
    "\n",
    "def parse_clean_mv_split(df, line_number, index):\n",
    "    \"\"\"Splits line using the \"|\" character and returns a List of clean data\"\"\"\n",
    "    if pd.isna(df.loc[line_number][index]):\n",
    "        return []\n",
    "    else:\n",
    "        # .replace(\" I \",\" | \")\n",
    "        return [cleanData(item) for item in re.split(\" \\| \", df.loc[line_number][index])]\n",
    "\n",
    "\n",
    "def parse_clean_mv_split_I(df, line_number, index):\n",
    "    \"\"\"Splits line using the \"I\" character and returns a List of clean data\"\"\"\n",
    "    # .replace(\" | \",\" I \")\n",
    "    return [cleanData(item) for item in re.split(\" I \", df.loc[line_number][index])]\n",
    "\n",
    "\n",
    "def parse_registry_template(df, template):\n",
    "    \"\"\"Controls the order of extracting data from the Excel sheet\n",
    "\n",
    "       Parameters:\n",
    "           df (dataframe): Panda's dataframe\n",
    "           template (dictionary): Dictionary to hold parse data\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    parse_pubmed(df, template)\n",
    "    parse_study(df, template)\n",
    "    parse_study_personnel(df, template)\n",
    "    parse_study_file(df, template)\n",
    "    parse_study_link(df, template)\n",
    "    parse_study_categorization(df, template)\n",
    "    parse_study_design(df, template)\n",
    "    parse_protocol(df, template)\n",
    "    parse_condition_or_disease(df, template)\n",
    "    parse_intervention(df, template)\n",
    "    parse_study_details(df, template)\n",
    "    parse_subject_human(df, template)\n",
    "    parse_model_organism(df, template)\n",
    "    parse_planned_visit(df, template)\n",
    "    parse_experiment(df, template)\n",
    "    parse_inclusion_exclusion(df, template)\n",
    "\n",
    "\n",
    "def parse_pubmed(df, template):\n",
    "    \"\"\"Parse the single valued pubmed_id\"\"\"\n",
    "\n",
    "    template['pubmed_id'] = parse_sv(df, STUDY_PUBMED, 2)\n",
    "\n",
    "\n",
    "def parse_study(df, template):\n",
    "    \"\"\"Parse top level single valued study information\"\"\"\n",
    "\n",
    "    template['study_identifier'] = parse_clean_sv(df, STUDY_IDENTIFIER, 2)\n",
    "    template['study_name'] = parse_clean_sv(df, STUDY_NAME, 2)\n",
    "    template['publication_title'] = parse_clean_sv(df, PUBLICATION_TITLE, 2)\n",
    "    template['study_objective'] = parse_clean_sv(df, STUDY_OBJECTIVE, 2)\n",
    "    template['study_description'] = parse_clean_sv(df, STUDY_DESCRIPTION, 2)\n",
    "    template['primary_institution_name'] = parse_clean_sv(df, PRIMARY_INSTITUTION_NAME, 2)\n",
    "\n",
    "\n",
    "def parse_study_personnel(df, template):\n",
    "    \"\"\"Parse the study personnel information\n",
    "    \n",
    "       There may be serveral study personnel with one person in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    studyPersonnel = []\n",
    "    personnel = list(df.loc[STUDY_PERSONNEL])\n",
    "    for idx, val in enumerate(personnel[2:], start=2):\n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "                \"personnel_id\": val,\n",
    "                \"honorific\": parse_clean_sv(df, STUDY_PERSONNEL + 1, idx),\n",
    "                \"last_name\": parse_clean_sv(df, STUDY_PERSONNEL + 2, idx),\n",
    "                \"first_name\": parse_clean_sv(df, STUDY_PERSONNEL + 3, idx),\n",
    "                \"suffixes\": parse_clean_sv(df, STUDY_PERSONNEL + 4, idx),\n",
    "                \"organization\": parse_clean_sv(df, STUDY_PERSONNEL + 5, idx),\n",
    "                \"orchid_id\": parse_clean_sv(df, STUDY_PERSONNEL + 6, idx),\n",
    "                \"email\": parse_clean_sv(df, STUDY_PERSONNEL + 7, idx),\n",
    "                \"seronet_title_in_study\":  parse_clean_sv(df, STUDY_PERSONNEL + 8, idx),\n",
    "                \"role_in_study\": parse_clean_sv(df, STUDY_PERSONNEL + 9, idx),\n",
    "                \"site_name\": parse_clean_sv(df, STUDY_PERSONNEL + 10, idx)\n",
    "            }\n",
    "            studyPersonnel.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    template['study_personnel'] = studyPersonnel\n",
    "\n",
    "\n",
    "def parse_study_file(df, template):\n",
    "    \"\"\"Parse the study file information\n",
    "    \n",
    "       There may be serveral study files with one study file in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    studyFile = []\n",
    "    study_files = list(df.loc[STUDY_FILE])\n",
    "    for idx, val in enumerate(study_files[2:], start=2): \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"study_file_name\": val,\n",
    "               \"study_file_description\": parse_clean_sv(df, STUDY_FILE + 1, idx),\n",
    "               \"study_file_type\": parse_clean_sv(df, STUDY_FILE + 2, idx)\n",
    "            }\n",
    "            studyFile.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    template['study_file'] = studyFile\n",
    "\n",
    "    \n",
    "def parse_study_link(df, template):\n",
    "    \"\"\"Parse the study link information\n",
    "    \n",
    "       There may be serveral study links with one study link in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "    studyLink = []\n",
    "    study_links = list(df.loc[STUDY_LINK])\n",
    "    for idx, val in enumerate(study_links[2:], start=2): \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"link_name\": val,\n",
    "               \"value\": parse_clean_sv(df, STUDY_LINK +1, idx)\n",
    "            }\n",
    "            studyLink.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    template['study_link'] = studyLink\n",
    "\n",
    "\n",
    "def parse_study_categorization(df, template):\n",
    "    \"\"\" Parse the Study Categorization section\"\"\"\n",
    "\n",
    "    # \n",
    "    # Research Focus\n",
    "    #\n",
    "    template['research_focus'] = parse_clean_sv(df, RESEARCH_FOCUS, 2)\n",
    "\n",
    "\n",
    "    #\n",
    "    # Study Type\n",
    "    #\n",
    "    template['study_type'] = parse_clean_sv(df, STUDY_TYPE, 2)\n",
    "\n",
    "    #\n",
    "    # Keywords \n",
    "    #\n",
    "    keyword = []\n",
    "    keywords = (list(df.loc[KEYWORDS])[2]).replace(\";\",\" | \").replace(\" I \", \"|\").replace(\",\",\"|\").split(\"|\")\n",
    "    for k in keywords:\n",
    "        keyword.append(k.strip())\n",
    "    template['keyword'] = keyword\n",
    "\n",
    "\n",
    "def parse_study_design(df, template):\n",
    "    \"\"\"Parse the Study Design section\"\"\"\n",
    "\n",
    "    template['clinical_study_design'] = parse_clean_sv(df, CLINICAL_STUDY_DESIGN, 2)\n",
    "    template['in_silico_model_type'] = parse_clean_sv(df, IN_SILICO_MODEL_TYPE, 2)\n",
    "\n",
    "\n",
    "def parse_protocol(df, template):\n",
    "    \"\"\"Parse the Protocol section\n",
    "\n",
    "       There may be serveral protocols with one protocol in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    protocol = {}\n",
    "    protocol['protocol_id'] = parse_clean_sv(df, PROTOCOL_ID, 2)\n",
    "    protocol['protocol_file_name'] = parse_clean_sv(df, PROTOCOL_FILE_NAME, 2)\n",
    "    protocol['protocol_name'] = parse_clean_sv(df, PROTOCOL_NAME, 2)\n",
    "    protocol['protocol_description'] = parse_clean_sv(df, PROTOCOL_DESCRIPTION, 2)\n",
    "    protocol['protocol_type'] = parse_clean_sv(df, PROTOCOL_TYPE, 2)\n",
    "\n",
    "    template['protocol'] = protocol\n",
    "\n",
    "\n",
    "def parse_condition_or_disease(df, template):\n",
    "    \"\"\"Parse the Condition or Disease line\n",
    "        \n",
    "        This line can contain one or more condtions current separated using \"I\".\n",
    "    \"\"\"\n",
    "    rhc = list(df.loc[REPORTED_HEALTH_CONDITION])[2].replace(\"|\",\" I \").replace(\",\", \" I \")\n",
    "    values = re.split(\" I \", rhc)\n",
    "    reported_health_condition = []\n",
    "    for c in values:\n",
    "        reported_health_condition.append(cleanData(c))\n",
    "\n",
    "    # temp = []\n",
    "    # for c in ' '.join(reported_health_condition).split('|'):\n",
    "    #     temp.append(c.strip())\n",
    "\n",
    "    template['reported_health_condition'] = reported_health_condition\n",
    "\n",
    "\n",
    "def parse_intervention(df, template):\n",
    "    \"\"\"Parse the Intervention Agent line\n",
    "\n",
    "        This line can contain one or more agents separated using \"|\"\n",
    "    \"\"\"\n",
    "\n",
    "    values = parse_clean_mv_split(df, SARS_COV_2_VACCINE_TYPE, 2)\n",
    "    vaccine_types = []\n",
    "    for v in values:\n",
    "        vaccine_types.append(cleanData(v))\n",
    "    template['sars_cov_2_vaccine_type'] = vaccine_types\n",
    "\n",
    "\n",
    "def parse_study_details(df, template):\n",
    "    \"\"\"Parse the Study Detail seciont\n",
    "        \n",
    "        Each line contains one single value.\n",
    "    \"\"\"\n",
    "\n",
    "    template['clinical_outcome_measure'] = parse_clean_sv(df, CLINICAL_OUTCOME_MEASURE, 2)\n",
    "    template['enrollment_start_date'] = parse_clean_sv(df, ENROLLMENT_START_DATE, 2)\n",
    "    template['enrollment_end_date'] = parse_clean_sv(df, ENROLLMENT_END_DATE, 2)\n",
    "    template['number_of_study_subjects'] = parse_clean_sv(df, NUMBER_OF_STUDY_SUBJECTS, 2)\n",
    "    template['age_unit'] = parse_clean_sv(df, AGE_UNIT, 2)\n",
    "    template['minimum_age'] = parse_clean_sv(df, MINIMUM_AGE, 2)\n",
    "    template['maximum_age'] = parse_clean_sv(df, MAXIMUM_AGE, 2)\n",
    "\n",
    "\n",
    "def parse_inclusion_exclusion(df, template):\n",
    "    \"\"\"Parse the inclusion/exclusion section\n",
    "\n",
    "       Some of the entries in this section are being treated as special cases,\n",
    "       because they eventually need to be treated as Yes/No facets in the CDT.\n",
    "    \"\"\"\n",
    "    inclusion_exclusion = []\n",
    "    ids = list(df.loc[INCLUSION_ID])\n",
    "    \n",
    "    #\n",
    "    # Set the following properties to \"Not Specified\"\n",
    "    # If they are in the template they will be updated to \"Yes\" or \"No\"\n",
    "    #\n",
    "    template['geriatric_subjects'] = \"Not Specified\"\n",
    "    template['pediatric_subjects'] = \"Not Specified\"\n",
    "    template['pregnant_subjects'] = \"Not Specified\"\n",
    "    template['sars_cov_2_antibodies_measured'] = \"Not Specified\"\n",
    "    template['survey_instrument_shared'] = \"Not Specified\"\n",
    "    template['who_disease_severity_scale_used'] = \"Not Specified\"\n",
    "\n",
    "    for idx, val in enumerate(ids[2:], start=2):\n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"inclusion_exculusion_id\": val,\n",
    "               \"inclusion_criterion\": parse_clean_sv(df, INCLUSION_CRITERION, idx),\n",
    "               \"inclusion_criterion_category\": parse_clean_sv(df, INCLUSION_CRITERION_CATEGORY, idx)\n",
    "            }\n",
    "            inclusion_exclusion.append(obj)\n",
    "            \n",
    "            if  obj['inclusion_criterion'] == \"Geriatric subjects\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['geriatric_subjects'] = \"Yes\"\n",
    "                else:\n",
    "                    template['geriatric_subjects'] = \"No\"\n",
    "\n",
    "            if  obj['inclusion_criterion'] == \"Pediatric subjects\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['pediatric_subjects'] = \"Yes\"\n",
    "                else:\n",
    "                    template['pediatric_subjects'] = \"No\"\n",
    "\n",
    "            if  obj['inclusion_criterion'] == \"Pregnant subjects\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['pregnant_subjects'] = \"Yes\"\n",
    "                else:\n",
    "                    template['pregnant_subjects'] = \"No\"\n",
    "\n",
    "            if  obj['inclusion_criterion'] == \"SARS-CoV-2 Antibodies Measured\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['sars_cov_2_antibodies_measured'] = \"Yes\"\n",
    "                else:\n",
    "                    template['sars_cov_2_antibodies_measured'] = \"No\"\n",
    "\n",
    "            if  obj['inclusion_criterion'] == \"Survey Instrument shared\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['survey_instrument_shared'] = \"Yes\"\n",
    "                else:\n",
    "                    template['survey_instrument_shared'] = \"No\"\n",
    "\n",
    "            if  obj['inclusion_criterion'] == \"WHO disease severity scale used\":\n",
    "                if obj['inclusion_criterion_category'] == \"inclusion\":\n",
    "                    template['who_disease_severity_scale_used'] = \"Yes\"\n",
    "                else:\n",
    "                    template['who_disease_severity_scale_used'] = \"No\"\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    template['inclusion_exclusion'] = inclusion_exclusion\n",
    "\n",
    "\n",
    "def parse_subject_human(df, template):\n",
    "    \"\"\"Parse the Subject Type: human section\n",
    "\n",
    "       Some rows in this section contain single value and some contain multi-valued content\n",
    "\n",
    "       There may be serveral entries with one entry in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    human_cohort = []\n",
    "    chorts = list(df.loc[HUMAN_ARM_ID])\n",
    "    for idx, val in enumerate(chorts[2:], start=2): \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"arm_id\": val,\n",
    "               \"arm_name\": parse_clean_sv(df, HUMAN_ARM_NAME, idx),\n",
    "               \"study_population_description\": parse_clean_sv(df, HUMAN_STUDY_POPULATION_DESCRIPTION, idx),\n",
    "               \"arm_type\": parse_clean_sv(df, HUMAN_ARM_TYPE, idx),\n",
    "               \"ethnicity\": parse_clean_mv_split(df, HUMAN_ETHNICITY, idx),\n",
    "               \"race\": parse_clean_mv_split(df, HUMAN_RACE, idx),\n",
    "               \"race_specify\": parse_clean_mv_split(df, HUMAN_RACE_SPECIFY, idx),\n",
    "               \"description\": parse_clean_sv(df, HUMAN_DESCRIPTION, idx),\n",
    "               \"sex_at_birth\": parse_clean_mv_split(df, HUMAN_SEX_AT_BIRTH, idx),\n",
    "               \"age_event\": parse_clean_sv(df, HUMAN_AGE_EVENT, idx),\n",
    "               \"subject_phenotype\": parse_clean_sv(df, HUMAN_SUBJECT_PHENOTYPE,idx),\n",
    "               \"assessment_name\": parse_clean_mv_split(df, HUMAN_ASSESSMENT_NAME, idx),\n",
    "               \"study_location\": parse_clean_mv_split(df, HUMAN_STUDY_LOCATION, idx),\n",
    "               \"measured_behavioral_or_pyschological_factor\": parse_clean_mv_split(df, HUMAN_MEASURED_BEHAVIORAL_OR_PYSCHOLOGICAL_FACTOR, idx),\n",
    "               \"measured_social_factor\": parse_clean_mv_split(df, HUMAN_MEASURED_SOCIAL_FACTOR, idx),\n",
    "               \"sars_cov_2_symptoms\": parse_clean_mv_split(df, HUMAN_SARS_COV_2_SYMPTOMS, idx),\n",
    "               \"assessment_clinical_and_demographic_data_provenance\": parse_clean_mv_split(df, HUMAN_ASSESSMENT_CLINICAL_AND_DEMOGRAPHIC_DATA_PROVENANCE, idx),\n",
    "               \"assessment_demographic_data_types_collected\": parse_clean_mv_split(df, HUMAN_ASSESSMENT_DEMOGRAPHIC_DATA_TYPES_COLLECTED, idx),\n",
    "               \"sars_cov_2_history\": parse_clean_mv_split(df, HUMAN_SARS_COV_2_HISTORY, idx),\n",
    "               \"sars_cov_2_vaccine_type\": parse_clean_mv_split(df, HUMAN_SARS_COV_2_VACCINE_TYPE, idx),\n",
    "               \"covid_19_disease_severity\": parse_clean_mv_split(df, HUMAN_COVID_19_DISEASE_SEVERITY, idx),\n",
    "               \"post_covid_19_symptoms\": parse_clean_mv_split(df, HUMAN_POST_COVID_19_SYMPTOMS, idx),\n",
    "               \"covid_19_complications\": parse_clean_mv_split(df, HUMAN_COVID_19_COMPLICATIONS, idx)\n",
    "            }\n",
    "            human_cohort.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    template['study_human_cohort'] = human_cohort\n",
    "\n",
    "\n",
    "def parse_model_organism(df, template):\n",
    "    \"\"\"Parse the Subject Type: model organism\n",
    "\n",
    "       Some rows in this section contain single value and some contain multi-valued content\n",
    "\n",
    "       There may be serveral entries with one entry in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "    model_cohort = []\n",
    "    chorts = list(df.loc[MODEL_ARM_ID])\n",
    "    for idx, val in enumerate(chorts[2:], start=2): \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"arm_id\": val,\n",
    "               \"arm_name\": parse_clean_sv(df, MODEL_ARM_NAME, idx),\n",
    "               \"study_population_description\": parse_clean_sv(df, MODEL_STUDY_POPULATION_DESCRIPTION, idx),\n",
    "               \"arm_type\": parse_clean_sv(df, MODEL_ARM_TYPE, idx),\n",
    "               \"genus_and_species\": parse_clean_mv_split(df, MODEL_SPECIES, idx),\n",
    "               \"biosample_type\": parse_clean_mv_split(df, MODEL_BIOSAMPLE_TYPE, idx),\n",
    "               \"strain_characteristics\": parse_clean_mv_split(df, MODEL_STRAIN_CHARACTERISTICS, idx),\n",
    "               \"sex_at_birth\": parse_clean_mv_split(df, MODEL_SEX_AT_BIRTH, idx),\n",
    "               \"age_event\": parse_clean_sv(df, MODEL_AGE_EVENT, idx),\n",
    "               \"subject_phenotype\": parse_clean_sv(df, MODEL_SUBJECT_PHENOTYPE, idx),\n",
    "               \"study_location\": parse_clean_mv_split(df, MODEL_STUDY_LOCATION, idx),\n",
    "               \"sars_cov_2_history\": parse_clean_mv_split(df, MODEL_SARS_COV_2_HISTORY, idx),\n",
    "               \"sars_cov_2_vaccine_type\": parse_clean_mv_split(df, MODEL_SARS_COV_2_VACCINE_TYPE, idx),\n",
    "               \"covid_19_disease_severity\": parse_clean_mv_split(df, MODEL_COVID_19_DISEASE_SEVERITY, idx),\n",
    "               \"post_covid_19_symptons\": parse_clean_mv_split(df, MODEL_POST_COVID_19_SYMPTOMS, idx),\n",
    "               \"covid_19_complications\": parse_clean_mv_split(df, MODEL_COVID_19_COMPLICATIONS, idx)\n",
    "            }\n",
    "            model_cohort.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    template['study_model_cohort'] = model_cohort\n",
    "\n",
    "\n",
    "def parse_planned_visit(df, template):\n",
    "    \"\"\"Parse the Planned Visit section\n",
    "\n",
    "       There may be serveral entries with one entry in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    plannedVisit = []\n",
    "    visits = list(df.loc[VISIT_ID])\n",
    "    for idx, val in enumerate(visits[2:], start=2):  \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"visit_id\": val,\n",
    "               \"visit_name\": parse_clean_sv(df, VISIT_NAME, idx),\n",
    "               \"visit_order_number\": parse_sv(df, VISIT_ORDER_NUMBER, idx),\n",
    "               \"visit_min_start_day\": parse_clean_sv(df, VISIT_MIN_START_DAY, idx),\n",
    "               \"visit_max_start_day\": parse_clean_sv(df, VISIT_MAX_START_DAY, idx),\n",
    "               \"visit_start_rule\": parse_clean_sv(df, VISIT_START_RULE, idx)\n",
    "            }\n",
    "            plannedVisit.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "    template['planned_visit'] = plannedVisit\n",
    "\n",
    "\n",
    "def parse_experiment(df, template):\n",
    "    \"\"\"Parse the Experiment section\n",
    "\n",
    "       Some rows in this section contain single value and some contain multi-valued content\n",
    "\n",
    "       There may be serveral entries with one entry in each column\n",
    "       spanning multiple lines in the spread sheet.\n",
    "    \"\"\"\n",
    "    experiment = []\n",
    "    experiments = list(df.loc[ASSOCIATED_ARM_IDS])\n",
    "    for idx, val in enumerate(experiments[2:], start=2): \n",
    "        if not pd.isna(val):\n",
    "            obj = {\n",
    "               \"arm_id\": [cleanData(item) for item in re.split(\" I \",val)],\n",
    "               \"associated_first_planned_visit_id\": [cleanData(item) for item in re.split(\" I \", df.loc[ASSOCIATED_FIRST_PLANNED_VISIT_ID][idx])],\n",
    "               \"assay_type\": parse_clean_sv(df, ASSAY_TYPE, idx),\n",
    "               \"experiment_name\": parse_clean_sv(df, EXPERIMENT_NAME, idx),\n",
    "               \"experiment_results_file_name\": parse_clean_sv(df, EXPERIMENT_RESULTS_FILE_NAME, idx),\n",
    "               \"biospecimen_type\": parse_clean_mv_split(df, BIOSPECIMEN_TYPE, idx),\n",
    "               \"biospecimen_collection_point\": parse_clean_mv_split(df, BIOSPECIMEN_COLLECTION_POINT, idx),\n",
    "               \"sars_cov_2_antigen\": parse_clean_mv_split(df, SARS_COV_2_ANTIGEN, idx),\n",
    "               \"assay_use\": parse_clean_sv(df, ASSAY_USE, idx),\n",
    "               \"manufacture\": parse_clean_sv(df, MANUFACTURER, idx),\n",
    "               \"catalog_number\": parse_clean_sv(df, CATALOG_NUMBER, idx),\n",
    "               \"virus_target\": parse_clean_mv_split(df, VIRUS_TARGET, idx),\n",
    "               \"antibody_isotype\": parse_clean_mv_split(df, ANTIBODY_ISOTYPE, idx),\n",
    "               \"reporting_units\": parse_clean_sv(df, REPORTING_UNITS, idx),\n",
    "               \"assay_reporting_format\": parse_clean_sv(df, ASSAY_REPORTING_FORMAT, idx)\n",
    "            }\n",
    "            experiment.append(obj)\n",
    "        else:\n",
    "            pass\n",
    "                                                                                 \n",
    "    template['experiment'] = experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83cc6da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DOWNLOADS = '~/Downloads'\n",
    "HENRY = 'seronet_reagent_110722_v2.txt'\n",
    "\n",
    "REAGENT_INFO = path.join(DOWNLOADS, HENRY)\n",
    "REAGENT_DF = pd.read_csv(REAGENT_INFO, sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f133b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_dict(pmid):\n",
    "    df_path = glob(path.join(\n",
    "        seroFxn.get_box_dir(box_base, pmid),\n",
    "        'templated_data',\n",
    "        f'PMID{pmid}*.xlsm'))[0]\n",
    "\n",
    "    tempdf = pd.read_excel(df_path, sheet_name = 0, header=None)\n",
    "    tempdf.index += 1\n",
    "    template = {}\n",
    "    parse_experiment(tempdf, template)\n",
    "\n",
    "    return template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f084a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_df_dict('34151306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b2d6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reagent_accession = []\n",
    "\n",
    "ID = []\n",
    "name = []\n",
    "description = []\n",
    "manufacturer = []\n",
    "catalog_number = []\n",
    "\n",
    "def join_type(args):\n",
    "    if isinstance(args, list):\n",
    "        arg_split = ' | '.join(args)\n",
    "    elif isinstance(args, str):\n",
    "        arg_split = args\n",
    "    else: \n",
    "        arg_split = []\n",
    "        pass\n",
    "    return arg_split\n",
    "\n",
    "for rows in range(len(REAGENT_DF)):\n",
    "    c_row = REAGENT_DF.iloc[rows]\n",
    "\n",
    "    if c_row['NAME'] is not np.nan: ## I NEED TO CHECK THE BLANKS TO SEE IF THERE IS ACTUALLY DATA IN THE SPREADSHEET\n",
    "        try: \n",
    "            PMID = re.findall('[\\d]{8}',c_row['USER_DEFINED_ID'])[0]\n",
    "    #         print(PMID)\n",
    "            # I need to pull in the correct PMID here\n",
    "\n",
    "            n = c_row['USER_DEFINED_ID'].split('-')\n",
    "            if len(n) > 1:\n",
    "                try:\n",
    "                    n = int(n[1]) - 1 \n",
    "                    template = get_df_dict(PMID)\n",
    "                    name.append(join_type(template['experiment'][n].get('sars_cov_2_antigen')))\n",
    "                    description.append(join_type(template['experiment'][n].get('assay_use')))\n",
    "                    manufacturer.append(join_type(template['experiment'][n].get('manufacture')))\n",
    "                    catalog_number.append(join_type(template['experiment'][n].get('catalog_number')))\n",
    "                except:\n",
    "                    print(f'error- {PMID}')\n",
    "                    pass\n",
    "        #             i = int(i) - 1 \n",
    "        #             \n",
    "\n",
    "            elif c_row['NAME'] == 'Reagents not curated': \n",
    "                ID.append(f'PMID{PMID}_reagents_not_curated')\n",
    "                name.append(f'Reagents not curated')\n",
    "                description.append('Reagents not curated for this experiment')\n",
    "                manufacturer.append('na')\n",
    "                catalog_number.append('na')\n",
    "\n",
    "\n",
    "            else: \n",
    "                pass\n",
    "        except:\n",
    "            print(c_row['USER_DEFINED_ID'])\n",
    "            pass\n",
    "    else:\n",
    "        ID.append(f'PMID{PMID}_reagents_not_curated')\n",
    "        name.append(f'Reagents not curated')\n",
    "        description.append('Reagents not curated for this experiment')\n",
    "        manufacturer.append('na')\n",
    "        catalog_number.append('na') \n",
    "        \n",
    "#             template['experiment'][i].get() == 'Reagents not curated': \n",
    "#         if (len(PMID) > 0) and (PMID not in used):\n",
    "#             PMID = PMID[0]\n",
    "\n",
    "#             box_base = \"~/Library/CloudStorage/Box-Box/SeroNet Public Data\"\n",
    "\n",
    "#             #File Paths\n",
    "#             BOX_BASE = seroFxn.get_box_dir(box_base, PMID)\n",
    "#             print(BOX_BASE)\n",
    "#             for i in range(len(template['experiment'])):\n",
    "#                 ID # need to make \n",
    "#                 reagent_accession #taken from henrys list \n",
    "\n",
    "\n",
    "#                 name.append(template['experiment'][i].get('sars_cov_2_antigen'))\n",
    "#                 description.append(template['experiment'][i].get('assay_use'))\n",
    "#                 manufacturer.append(template['experiment'][i].get('manufacture'))\n",
    "#                 catalog_number.append(template['experiment'][i].get('catalog_number'))\n",
    "#     #             parse_experiment(PMID, )\n",
    "\n",
    "#             used.append(PMID)\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e057bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_DEFINED_ID</th>\n",
       "      <th>REAGENT_ACCESSION</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>catalog_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMID35504289_reagentID-01</td>\n",
       "      <td>ESR29838</td>\n",
       "      <td>Full Length Spike Trimer</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMID35504289_reagents_not_curated</td>\n",
       "      <td>ESR29839</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMID35455241_reagentID-01</td>\n",
       "      <td>ESR30061</td>\n",
       "      <td>Wild type Spike I Wild type RBD I Omicron RBD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMID35455241_reagentID-02</td>\n",
       "      <td>ESR30062</td>\n",
       "      <td>Wild type Spike I Wild type RBD I Omicron RBD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMID35455241_reagentID-03</td>\n",
       "      <td>ESR30063</td>\n",
       "      <td>Wild type Spike I Wild type RBD I Omicron RBD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PMID35455241_reagentID-04</td>\n",
       "      <td>ESR30064</td>\n",
       "      <td>Wild type Spike I Wild type RBD I Omicron RBD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PMID35455241_reagentID-05</td>\n",
       "      <td>ESR30065</td>\n",
       "      <td>Wild type Spike I Wild type RBD I Omicron RBD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PMID35427477_reagentID-01</td>\n",
       "      <td>ESR30090</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PMID33440148_reagents_not_curated</td>\n",
       "      <td>ESR30086</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PMID34696403_reagentID-01</td>\n",
       "      <td>ESR30087</td>\n",
       "      <td>Receptor Binding Domain (RBD) | S2</td>\n",
       "      <td>FDA EUA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PMID34696403_reagentID-02</td>\n",
       "      <td>ESR30088</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PMID34696403_reagentID-03</td>\n",
       "      <td>ESR30089</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PMID35427477_reagentID-02</td>\n",
       "      <td>ESR30091</td>\n",
       "      <td>Receptor Binding Domain (RBD)</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PMID35427477_reagentID-03</td>\n",
       "      <td>ESR30092</td>\n",
       "      <td>Receptor Binding Domain (RBD) | Full Length Sp...</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PMID35427477_reagentID-04</td>\n",
       "      <td>ESR30093</td>\n",
       "      <td>Receptor Binding Domain (RBD) | Full Length Sp...</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PMID35427477_reagents_not_curated</td>\n",
       "      <td>ESR30094</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PMID35348368_reagentID-01</td>\n",
       "      <td>ESR30095</td>\n",
       "      <td>S1 | S2 | Full Length Spike Trimer | Receptor ...</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PMID35348368_reagentID-02</td>\n",
       "      <td>ESR30096</td>\n",
       "      <td>S1 | S2 | Full Length Spike Trimer | Receptor ...</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PMID35348368_reagentID-03</td>\n",
       "      <td>ESR30097</td>\n",
       "      <td>S1 | S2 | Full Length Spike Trimer | Receptor ...</td>\n",
       "      <td></td>\n",
       "      <td>components from multiple manufacturers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PMID35348368_reagents_not_curated</td>\n",
       "      <td>ESR30098</td>\n",
       "      <td>Reagents not curated</td>\n",
       "      <td>Reagents not curated for this experiment</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      USER_DEFINED_ID REAGENT_ACCESSION  \\\n",
       "0           PMID35504289_reagentID-01          ESR29838   \n",
       "1   PMID35504289_reagents_not_curated          ESR29839   \n",
       "2           PMID35455241_reagentID-01          ESR30061   \n",
       "3           PMID35455241_reagentID-02          ESR30062   \n",
       "4           PMID35455241_reagentID-03          ESR30063   \n",
       "5           PMID35455241_reagentID-04          ESR30064   \n",
       "6           PMID35455241_reagentID-05          ESR30065   \n",
       "7           PMID35427477_reagentID-01          ESR30090   \n",
       "8   PMID33440148_reagents_not_curated          ESR30086   \n",
       "9           PMID34696403_reagentID-01          ESR30087   \n",
       "10          PMID34696403_reagentID-02          ESR30088   \n",
       "11          PMID34696403_reagentID-03          ESR30089   \n",
       "12          PMID35427477_reagentID-02          ESR30091   \n",
       "13          PMID35427477_reagentID-03          ESR30092   \n",
       "14          PMID35427477_reagentID-04          ESR30093   \n",
       "15  PMID35427477_reagents_not_curated          ESR30094   \n",
       "16          PMID35348368_reagentID-01          ESR30095   \n",
       "17          PMID35348368_reagentID-02          ESR30096   \n",
       "18          PMID35348368_reagentID-03          ESR30097   \n",
       "19  PMID35348368_reagents_not_curated          ESR30098   \n",
       "\n",
       "                                                 name  \\\n",
       "0                            Full Length Spike Trimer   \n",
       "1                                Reagents not curated   \n",
       "2       Wild type Spike I Wild type RBD I Omicron RBD   \n",
       "3       Wild type Spike I Wild type RBD I Omicron RBD   \n",
       "4       Wild type Spike I Wild type RBD I Omicron RBD   \n",
       "5       Wild type Spike I Wild type RBD I Omicron RBD   \n",
       "6       Wild type Spike I Wild type RBD I Omicron RBD   \n",
       "7                                Reagents not curated   \n",
       "8                                Reagents not curated   \n",
       "9                  Receptor Binding Domain (RBD) | S2   \n",
       "10                               Reagents not curated   \n",
       "11                               Reagents not curated   \n",
       "12                      Receptor Binding Domain (RBD)   \n",
       "13  Receptor Binding Domain (RBD) | Full Length Sp...   \n",
       "14  Receptor Binding Domain (RBD) | Full Length Sp...   \n",
       "15                               Reagents not curated   \n",
       "16  S1 | S2 | Full Length Spike Trimer | Receptor ...   \n",
       "17  S1 | S2 | Full Length Spike Trimer | Receptor ...   \n",
       "18  S1 | S2 | Full Length Spike Trimer | Receptor ...   \n",
       "19                               Reagents not curated   \n",
       "\n",
       "                                 description  \\\n",
       "0                                              \n",
       "1   Reagents not curated for this experiment   \n",
       "2                                              \n",
       "3                                              \n",
       "4                                              \n",
       "5                                              \n",
       "6                                              \n",
       "7   Reagents not curated for this experiment   \n",
       "8   Reagents not curated for this experiment   \n",
       "9                                    FDA EUA   \n",
       "10  Reagents not curated for this experiment   \n",
       "11  Reagents not curated for this experiment   \n",
       "12                                             \n",
       "13                                             \n",
       "14                                             \n",
       "15  Reagents not curated for this experiment   \n",
       "16                                             \n",
       "17                                             \n",
       "18                                             \n",
       "19  Reagents not curated for this experiment   \n",
       "\n",
       "                              manufacturer catalog_number  \n",
       "0                                                          \n",
       "1                                       na             na  \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "5                                                          \n",
       "6                                                          \n",
       "7                                       na             na  \n",
       "8                                       na             na  \n",
       "9                                                          \n",
       "10                                      na             na  \n",
       "11                                      na             na  \n",
       "12  components from multiple manufacturers                 \n",
       "13  components from multiple manufacturers                 \n",
       "14  components from multiple manufacturers                 \n",
       "15                                      na             na  \n",
       "16  components from multiple manufacturers                 \n",
       "17  components from multiple manufacturers                 \n",
       "18  components from multiple manufacturers                 \n",
       "19                                      na             na  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.DataFrame({\n",
    "    \"USER_DEFINED_ID\":REAGENT_DF['USER_DEFINED_ID'],\n",
    "    \"REAGENT_ACCESSION\":REAGENT_DF['REAGENT_ACCESSION'],\n",
    "    \"name\":name,\n",
    "    \"description\":description,\n",
    "    \"manufacturer\":manufacturer,\n",
    "    \"catalog_number\":catalog_number\n",
    "    \n",
    "})\n",
    "\n",
    "out.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05c116f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"./reagentUpdate_check-10-26-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b4bc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USER_DEFINED_ID             PMID33830946_reagents_not_curated\n",
       "REAGENT_ACCESSION                                    ESR30106\n",
       "name                                     Reagents not curated\n",
       "description          Reagents not curated for this experiment\n",
       "manufacturer                                               na\n",
       "catalog_number                                             na\n",
       "Name: 27, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.iloc[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656dd6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
